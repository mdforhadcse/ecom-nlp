{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-13T05:39:59.493033Z",
     "start_time": "2025-12-13T05:39:58.968032Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import emoji\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "import html\n",
    "import string"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T05:39:59.500904Z",
     "start_time": "2025-12-13T05:39:59.498276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare folders\n",
    "# if the folder structure not exists, then i will create\n",
    "DATA_RAW = Path(\"data/raw\"); DATA_RAW.mkdir(parents=True, exist_ok=True)\n",
    "DATA_PROCESSED = Path(\"data/processed\"); DATA_PROCESSED.mkdir(parents=True, exist_ok=True)"
   ],
   "id": "1ef37a0f1196b07",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T05:39:59.728247Z",
     "start_time": "2025-12-13T05:39:59.506468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "CSV_PATH = DATA_RAW / \"dataset.csv\"\n",
    "df = pd.read_csv(CSV_PATH, encoding=\"utf-8\")"
   ],
   "id": "1490041b8972aa7f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T05:39:59.837195Z",
     "start_time": "2025-12-13T05:39:59.736956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n=== Columns ===\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "print(\"\\nShape:\", df.shape)\n",
    "\n",
    "print(\"\\nNulls per column:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "if \"Sentiment\" in df.columns:\n",
    "    print(\"\\nSentiment distribution:\")\n",
    "    print(df[\"Sentiment\"].value_counts(dropna=False))\n",
    "\n",
    "if \"Emotion\" in df.columns:\n",
    "    print(\"\\nEmotion distribution:\")\n",
    "    print(df[\"Emotion\"].value_counts(dropna=False))\n",
    "\n",
    "if \"Product Name\" in df.columns:\n",
    "    print(\"\\nUnique Product Names:\", df[\"Product Name\"].nunique())\n",
    "if \"Product Category\" in df.columns:\n",
    "    print(\"Unique Product Categories:\", df[\"Product Category\"].nunique())\n",
    "if \"Review\" in df.columns:\n",
    "    print(\"\\nUnique review distribution:\", df[\"Review\"].nunique())"
   ],
   "id": "bfa14e94694c55fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Columns ===\n",
      "['Rating', 'Review', 'Product Name', 'Product Category', 'Emotion', 'Data Source', 'Sentiment']\n",
      "\n",
      "Shape: (78130, 7)\n",
      "\n",
      "Nulls per column:\n",
      "Rating              0\n",
      "Review              0\n",
      "Product Name        0\n",
      "Product Category    0\n",
      "Emotion             0\n",
      "Data Source         0\n",
      "Sentiment           0\n",
      "dtype: int64\n",
      "\n",
      "Sentiment distribution:\n",
      "Sentiment\n",
      "Positive    67268\n",
      "Negative    10862\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Emotion distribution:\n",
      "Emotion\n",
      "Happy      46635\n",
      "Love       20633\n",
      "Sadness     6533\n",
      "Anger       3171\n",
      "Fear        1158\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique Product Names: 2476\n",
      "Unique Product Categories: 152\n",
      "\n",
      "Unique review distribution: 64147\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T05:39:59.999033Z",
     "start_time": "2025-12-13T05:39:59.978123Z"
    }
   },
   "cell_type": "code",
   "source": "df_dedup = df.drop_duplicates(subset=[\"Review\"], keep=\"first\").reset_index(drop=True)",
   "id": "fb27587704e0ea22",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T05:40:03.537489Z",
     "start_time": "2025-12-13T05:40:03.234126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_dedup_path = DATA_PROCESSED / \"dataset_dedup.csv\"\n",
    "df_dedup.to_csv(data_dedup_path, index=False, encoding=\"utf-8\")"
   ],
   "id": "6a0e3774c4e1011a",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T05:40:05.408897Z",
     "start_time": "2025-12-13T05:40:05.337925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"After dedup:\", len(df_dedup))\n",
    "print(\"Removed:\", len(df) - len(df_dedup))\n",
    "\n",
    "print(\"\\nShape:\", df_dedup.shape)\n",
    "\n",
    "if \"Sentiment\" in df_dedup.columns:\n",
    "    print(\"\\nSentiment distribution:\")\n",
    "    print(df_dedup[\"Sentiment\"].value_counts(dropna=False))\n",
    "\n",
    "if \"Emotion\" in df_dedup.columns:\n",
    "    print(\"\\nEmotion distribution:\")\n",
    "    print(df_dedup[\"Emotion\"].value_counts(dropna=False))\n",
    "\n",
    "if \"Product Name\" in df_dedup.columns:\n",
    "    print(\"\\nUnique Product Names:\", df_dedup[\"Product Name\"].nunique())\n",
    "if \"Product Category\" in df_dedup.columns:\n",
    "    print(\"Unique Product Categories:\", df_dedup[\"Product Category\"].nunique())\n",
    "if \"Review\" in df_dedup.columns:\n",
    "    print(\"\\nUnique review distribution:\", df_dedup[\"Review\"].nunique())"
   ],
   "id": "2da78d8163d08fbd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dedup: 64147\n",
      "Removed: 13983\n",
      "\n",
      "Shape: (64147, 7)\n",
      "\n",
      "Sentiment distribution:\n",
      "Sentiment\n",
      "Positive    53692\n",
      "Negative    10455\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Emotion distribution:\n",
      "Emotion\n",
      "Happy      37654\n",
      "Love       16038\n",
      "Sadness     6285\n",
      "Anger       3047\n",
      "Fear        1123\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique Product Names: 2361\n",
      "Unique Product Categories: 143\n",
      "\n",
      "Unique review distribution: 64147\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T05:40:10.575484Z",
     "start_time": "2025-12-13T05:40:06.947368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "TEXT_COL = \"Review\"  # change if needed\n",
    "\n",
    "# df = pd.read_csv(IN_PATH, encoding=\"utf-8\")\n",
    "\n",
    "# If you want to treat \"ğŸ˜ğŸ˜!!!\" as emoji-only, keep punctuation removal ON.\n",
    "ALLOW_PUNCT = True\n",
    "\n",
    "PUNCT_SPACES_RE = re.compile(r\"[\\s\\.\\,\\!\\?\\:\\;\\-\\_\\(\\)\\[\\]\\{\\}\\'\\\"\\+\\=\\*\\/\\\\\\|@#\\$%\\^&~`]+\")\n",
    "\n",
    "def is_emoji_only(text: str) -> bool:\n",
    "    if not isinstance(text, str):\n",
    "        return False\n",
    "    s = text.strip()\n",
    "    if s == \"\":\n",
    "        return True  # if you also want to remove empty reviews, change to True\n",
    "\n",
    "    # remove all emojis\n",
    "    s_no_emoji = emoji.replace_emoji(s, replace=\"\").strip()\n",
    "\n",
    "    # optionally remove punctuation/spaces too (so \"ğŸ˜ğŸ˜!!!\" becomes empty)\n",
    "    if ALLOW_PUNCT:\n",
    "        s_no_emoji = PUNCT_SPACES_RE.sub(\"\", s_no_emoji).strip()\n",
    "\n",
    "    # If nothing left => emoji-only\n",
    "    return s_no_emoji == \"\"\n",
    "\n",
    "mask = df_dedup[TEXT_COL].apply(is_emoji_only)\n",
    "\n",
    "print(\"Total rows after dedup:\", len(df_dedup))\n",
    "print(\"Emoji-only rows:\", int(mask.sum()))\n",
    "print(\"\\nExamples (will be removed):\")\n",
    "print(df_dedup.loc[mask, TEXT_COL].head(20).to_list())\n"
   ],
   "id": "5ebc5bcd9dfe5c40",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows after dedup: 64147\n",
      "Emoji-only rows: 114\n",
      "\n",
      "Examples (will be removed):\n",
      "['ğŸ‘', 'ğŸ’¯ğŸ’¯ğŸ’¯', 'ğŸ”¥', 'ğŸ˜ğŸ˜ğŸ˜', 'ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘', 'ğŸ¥°ğŸ¥°ğŸ¥°ğŸ¥°ğŸ¥°ğŸ¥°', 'ğŸ˜ŠğŸ˜ŠğŸ˜Š', 'ğŸ˜', 'ğŸ’ğŸ’ğŸ¥€', 'ğŸ¥°ğŸ’šğŸ€', 'ğŸ˜ğŸ¥°ğŸ¥°', 'ğŸ’¯ğŸ’¯', 'ğŸ˜™ğŸ˜™ğŸ˜™ğŸ˜™', 'ğŸ˜ğŸ˜', 'ğŸ™‚', 'ğŸ‘ğŸ‘ğŸ‘', 'â¤ï¸â¤ï¸', 'ğŸ¥°ğŸ–¤', 'ğŸ’–ğŸ’–', 'â™¥ï¸â™¥ï¸â™¥ï¸â™¥']\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T05:43:31.489523Z",
     "start_time": "2025-12-13T05:43:31.136208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_dedup_emoji_path = DATA_PROCESSED / \"dataset_dedup_emoji.csv\"\n",
    "df_dedup_emoji = df_dedup.loc[~mask].reset_index(drop=True)\n",
    "df_dedup_emoji.to_csv(df_dedup_emoji_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"\\nAfter removal:\", len(df_dedup_emoji))"
   ],
   "id": "87f9cfc2f392988d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After removal: 64033\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T05:46:47.101477Z",
     "start_time": "2025-12-13T05:46:46.990453Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if \"Sentiment\" in df_dedup_emoji.columns:\n",
    "    print(\"\\nSentiment distribution:\")\n",
    "    print(df_dedup_emoji[\"Sentiment\"].value_counts(dropna=False))\n",
    "\n",
    "if \"Emotion\" in df_dedup_emoji.columns:\n",
    "    print(\"\\nEmotion distribution:\")\n",
    "    print(df_dedup_emoji[\"Emotion\"].value_counts(dropna=False))\n",
    "\n",
    "if \"Product Name\" in df_dedup_emoji.columns:\n",
    "    print(\"\\nUnique Product Names:\", df_dedup_emoji[\"Product Name\"].nunique())\n",
    "if \"Product Category\" in df_dedup_emoji.columns:\n",
    "    print(\"Unique Product Categories:\", df_dedup_emoji[\"Product Category\"].nunique())\n",
    "if \"Review\" in df_dedup_emoji.columns:\n",
    "    print(\"\\nUnique review distribution:\", df_dedup_emoji[\"Review\"].nunique())"
   ],
   "id": "c05aa04a6d36da57",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentiment distribution:\n",
      "Sentiment\n",
      "Positive    53586\n",
      "Negative    10447\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Emotion distribution:\n",
      "Emotion\n",
      "Happy      37606\n",
      "Love       15980\n",
      "Sadness     6282\n",
      "Anger       3043\n",
      "Fear        1122\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique Product Names: 2361\n",
      "Unique Product Categories: 143\n",
      "\n",
      "Unique review distribution: 64033\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T06:32:57.106556Z",
     "start_time": "2025-12-13T06:32:54.184057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------------- Email ----------------\n",
    "EMAIL_RE = re.compile(r\"\\b[A-Z0-9._%+-]+@[A-Z0-9.-]+\\.[A-Z]{2,}\\b\", re.IGNORECASE)\n",
    "\n",
    "# ---------------- URLs ----------------\n",
    "URL_SCHEME_RE = re.compile(r\"\\b(?:https?://|ftp://)\\S+\\b\", re.IGNORECASE)\n",
    "URL_WWW_RE    = re.compile(r\"\\bwww\\.\\S+\\b\", re.IGNORECASE)\n",
    "BARE_DOMAIN_RE = re.compile(\n",
    "    r\"\\b(?:[a-z0-9-]+\\.)+(?:com|net|org|io|co|bd|uk|us|in|me|app|dev|ai|shop|store|xyz|info)\\b(?:/\\S*)?\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "# ---------------- Phone numbers ----------------\n",
    "BD_PHONE_RE = re.compile(r\"(?<!\\d)(?:\\+?88)?01[3-9]\\d{8}(?!\\d)\")\n",
    "PHONE_CANDIDATE_RE = re.compile(r\"(?:\\+?\\d[\\d\\-\\s\\(\\)]{6,}\\d)\")\n",
    "\n",
    "def has_phone(text: str) -> bool:\n",
    "    if not isinstance(text, str):\n",
    "        return False\n",
    "    t = text.strip()\n",
    "    if t == \"\":\n",
    "        return False\n",
    "\n",
    "    if BD_PHONE_RE.search(t):\n",
    "        return True\n",
    "\n",
    "    for m in PHONE_CANDIDATE_RE.finditer(t):\n",
    "        digits = re.sub(r\"\\D\", \"\", m.group(0))\n",
    "        if len(digits) >= 9:   # make 10 for stricter\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# ---------------- Order / Tracking / Invoice IDs (English + Bangla) ----------------\n",
    "ORDER_KEYWORDS_RE = re.compile(\n",
    "    r\"\\b(\"\n",
    "    # English\n",
    "    r\"order\\s*(id|no|number)|\"\n",
    "    r\"invoice\\s*(id|no|number)|\"\n",
    "    r\"tracking\\s*(id|no|number)|\"\n",
    "    r\"track\\s*(id|no|number)|\"\n",
    "    r\"consignment\\s*(id|no|number)|\"\n",
    "    r\"parcel\\s*(id|no|number)|\"\n",
    "    r\"shipment\\s*(id|no|number)|\"\n",
    "    r\"waybill|awb|\"\n",
    "    r\"reference\\s*(id|no|number)|\"\n",
    "    r\"ref\\s*(id|no|number)\"\n",
    "    r\")\\b\"\n",
    "    r\"|\"\n",
    "    r\"(à¦…à¦°à§à¦¡à¦¾à¦°|à¦…à¦°à§à¦¡à¦¾à¦°\\s*à¦†à¦‡à¦¡à¦¿|à¦…à¦°à§à¦¡à¦¾à¦°\\s*à¦¨à¦‚|à¦…à¦°à§à¦¡à¦¾à¦°\\s*à¦¨à¦®à§à¦¬à¦°|à¦…à¦°à§à¦¡à¦¾à¦°\\s*à¦¨à¦¾à¦®à§à¦¬à¦¾à¦°|\"\n",
    "    r\"à¦‡à¦¨à¦­à¦¯à¦¼à§‡à¦¸|à¦‡à¦¨à¦­à§Ÿà§‡à¦¸|à¦‡à¦¨à¦­à¦¯à¦¼à§‡à¦¸\\s*à¦†à¦‡à¦¡à¦¿|à¦‡à¦¨à¦­à§Ÿà§‡à¦¸\\s*à¦†à¦‡à¦¡à¦¿|à¦‡à¦¨à¦­à¦¯à¦¼à§‡à¦¸\\s*à¦¨à¦‚|à¦‡à¦¨à¦­à§Ÿà§‡à¦¸\\s*à¦¨à¦‚|\"\n",
    "    r\"à¦Ÿà§à¦°à§à¦¯à¦¾à¦•à¦¿à¦‚|à¦Ÿà§à¦°à§à¦¯à¦¾à¦•à¦¿à¦‚\\s*à¦†à¦‡à¦¡à¦¿|à¦Ÿà§à¦°à§à¦¯à¦¾à¦•à¦¿à¦‚\\s*à¦¨à¦‚|à¦Ÿà§à¦°à§à¦¯à¦¾à¦•à¦¿à¦‚\\s*à¦¨à¦®à§à¦¬à¦°|\"\n",
    "    r\"à¦•à¦¨à¦¸à¦¾à¦‡à¦¨à¦®à§‡à¦¨à§à¦Ÿ|à¦•à¦¨à¦¸à¦¾à¦‡à¦¨à¦®à§‡à¦¨à§à¦Ÿ\\s*à¦¨à¦‚|à¦•à¦¨à¦¸à¦¾à¦‡à¦¨à¦®à§‡à¦¨à§à¦Ÿ\\s*à¦¨à¦®à§à¦¬à¦°|\"\n",
    "    r\"à¦ªà¦¾à¦°à§à¦¸à§‡à¦²|à¦ªà¦¾à¦°à§à¦¸à§‡à¦²\\s*à¦¨à¦‚|à¦ªà¦¾à¦°à§à¦¸à§‡à¦²\\s*à¦¨à¦®à§à¦¬à¦°|\"\n",
    "    r\"à¦¶à¦¿à¦ªà¦®à§‡à¦¨à§à¦Ÿ|à¦¶à¦¿à¦ªà¦®à§‡à¦¨à§à¦Ÿ\\s*à¦†à¦‡à¦¡à¦¿|\"\n",
    "    r\"à¦“à¦¯à¦¼à§‡ à¦¬à¦¿à¦²|à¦“à§Ÿà§‡à¦¬à¦¿à¦²|à¦“à§Ÿà§‡ à¦¬à¦¿à¦²|\"\n",
    "    r\"à¦°à§‡à¦«à¦¾à¦°à§‡à¦¨à§à¦¸|à¦°à§‡à¦«\\s*à¦†à¦‡à¦¡à¦¿|à¦°à§‡à¦«à¦¾à¦°à§‡à¦¨à§à¦¸\\s*à¦¨à¦‚|à¦°à§‡à¦«à¦¾à¦°à§‡à¦¨à§à¦¸\\s*à¦¨à¦®à§à¦¬à¦°)\"\n",
    "    ,\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "# keyword then an ID-like token nearby (works for Bangla keywords too)\n",
    "ORDER_ID_NEAR_KEYWORD_RE = re.compile(\n",
    "    r\"(\"  # keyword group (English or Bangla)\n",
    "    r\"(?:order\\s*(?:id|no|number)|invoice\\s*(?:id|no|number)|tracking\\s*(?:id|no|number)|\"\n",
    "    r\"consignment\\s*(?:id|no|number)|shipment\\s*(?:id|no|number)|waybill|awb|reference\\s*(?:id|no|number)|ref\\s*(?:id|no|number))\"\n",
    "    r\"|\"\n",
    "    r\"(?:à¦…à¦°à§à¦¡à¦¾à¦°\\s*à¦†à¦‡à¦¡à¦¿|à¦…à¦°à§à¦¡à¦¾à¦°\\s*à¦¨à¦‚|à¦…à¦°à§à¦¡à¦¾à¦°\\s*à¦¨à¦®à§à¦¬à¦°|à¦‡à¦¨à¦­à¦¯à¦¼à§‡à¦¸\\s*à¦†à¦‡à¦¡à¦¿|à¦‡à¦¨à¦­à§Ÿà§‡à¦¸\\s*à¦†à¦‡à¦¡à¦¿|à¦‡à¦¨à¦­à¦¯à¦¼à§‡à¦¸\\s*à¦¨à¦‚|à¦‡à¦¨à¦­à§Ÿà§‡à¦¸\\s*à¦¨à¦‚|\"\n",
    "    r\"à¦Ÿà§à¦°à§à¦¯à¦¾à¦•à¦¿à¦‚\\s*à¦†à¦‡à¦¡à¦¿|à¦Ÿà§à¦°à§à¦¯à¦¾à¦•à¦¿à¦‚\\s*à¦¨à¦‚|à¦Ÿà§à¦°à§à¦¯à¦¾à¦•à¦¿à¦‚\\s*à¦¨à¦®à§à¦¬à¦°|à¦•à¦¨à¦¸à¦¾à¦‡à¦¨à¦®à§‡à¦¨à§à¦Ÿ\\s*à¦¨à¦‚|à¦•à¦¨à¦¸à¦¾à¦‡à¦¨à¦®à§‡à¦¨à§à¦Ÿ\\s*à¦¨à¦®à§à¦¬à¦°|\"\n",
    "    r\"à¦ªà¦¾à¦°à§à¦¸à§‡à¦²\\s*à¦¨à¦‚|à¦ªà¦¾à¦°à§à¦¸à§‡à¦²\\s*à¦¨à¦®à§à¦¬à¦°|à¦¶à¦¿à¦ªà¦®à§‡à¦¨à§à¦Ÿ\\s*à¦†à¦‡à¦¡à¦¿|à¦“à¦¯à¦¼à§‡ à¦¬à¦¿à¦²|à¦“à§Ÿà§‡à¦¬à¦¿à¦²|à¦“à§Ÿà§‡ à¦¬à¦¿à¦²|à¦°à§‡à¦«à¦¾à¦°à§‡à¦¨à§à¦¸\\s*à¦¨à¦‚|à¦°à§‡à¦«à¦¾à¦°à§‡à¦¨à§à¦¸\\s*à¦¨à¦®à§à¦¬à¦°|à¦°à§‡à¦«\\s*à¦†à¦‡à¦¡à¦¿)\"\n",
    "    r\")\"\n",
    "    r\"\\s*[:#\\-]?\\s*\"\n",
    "    r\"([A-Z0-9][A-Z0-9\\-_/]{3,})\",  # ID token\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "DIGITS_HEAVY_TOKEN_RE = re.compile(r\"\\b[A-Z0-9\\-_/]{5,}\\b\", re.IGNORECASE)\n",
    "\n",
    "def looks_like_id(token: str) -> bool:\n",
    "    digits = sum(ch.isdigit() for ch in token)\n",
    "    return digits >= 6  # requires enough digits to reduce false positives\n",
    "\n",
    "def has_order_id(text: str) -> bool:\n",
    "    if not isinstance(text, str):\n",
    "        return False\n",
    "    t = text.strip()\n",
    "    if t == \"\":\n",
    "        return False\n",
    "\n",
    "    m = ORDER_ID_NEAR_KEYWORD_RE.search(t)\n",
    "    if m and looks_like_id(m.group(2)):\n",
    "        return True\n",
    "\n",
    "    if ORDER_KEYWORDS_RE.search(t):\n",
    "        for tok in DIGITS_HEAVY_TOKEN_RE.findall(t):\n",
    "            if looks_like_id(tok):\n",
    "                return True\n",
    "\n",
    "    return False\n",
    "\n",
    "# ---------------- Combined filter ----------------\n",
    "def should_remove(text: str) -> bool:\n",
    "    if not isinstance(text, str):\n",
    "        return False\n",
    "    t = text.strip()\n",
    "    if t == \"\":\n",
    "        return False\n",
    "    return (\n",
    "        EMAIL_RE.search(t) is not None\n",
    "        or URL_SCHEME_RE.search(t) is not None\n",
    "        or URL_WWW_RE.search(t) is not None\n",
    "        or BARE_DOMAIN_RE.search(t) is not None\n",
    "        or has_phone(t)\n",
    "        or has_order_id(t)\n",
    "    )\n",
    "\n",
    "mask = df_dedup_emoji[TEXT_COL].apply(should_remove)\n",
    "\n",
    "print(\"Total rows after dedup & emoji:\", len(df_dedup_emoji))\n",
    "print(\"Rows removed (email/url/phone/order-id):\", int(mask.sum()))\n",
    "\n",
    "print(\"\\nExamples (will be removed):\")\n",
    "print(df_dedup_emoji.loc[mask, TEXT_COL].head(30).to_list())\n"
   ],
   "id": "e48b32a48fdd07db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 64033\n",
      "Rows removed (email/url/phone/order-id): 87\n",
      "\n",
      "Examples (will be removed):\n",
      "['à¦•à§‡à¦¨à¦¾à¦° à¦†à¦—à§‡ à¦¦à§‡à¦–à§‡ à¦†à¦¸à§à¦¨ à¦­à¦¿à¦¡à¦¿à¦“à¥¤à¥¤ à¦¸à¦¾à¦š à¦•à¦°à§à¦¨ PRB786 à¦²à¦¿à¦–à§‡ youtube,facebook,google,tiktok, url link -https://youtube.com/shorts/HRgKsgam3p0?si=Kn9n93Gr8h076ggE', 'à¦…à¦°à§à¦¡à¦¿à¦¨à¦¾à¦°à¦¿ à¦†à¦‡à¦Ÿà¦¿à¦¤à§‡ ordinaryit.com à¦ à¦«à§à¦°à¦¿à¦²à§à¦¯à¦¾à¦¨à§à¦¸à¦¿à¦‚ à¦²à§‡à¦–à¦¾à¦²à§‡à¦–à¦¿à¦° à¦•à¦¾à¦œ à¦•à¦°à¦¾à¦° à¦œà¦¨à§à¦¯ à¦¨à¦¿à¦¯à¦¼à§‡à¦›à¦¿ à¦…à¦¨à§‡à¦• à¦¸à§à¦¨à§à¦¦à¦° à¦•à¦¾à¦œ à¦•à¦°à¦›à§‡à¥¤', 'à¦ªà§à¦²à§‡ à¦¬à¦¾à¦Ÿà¦¨à§‡ à¦•à¦¾à¦œ à¦•à¦°à¦¤à§‡à¦›à§‡ à¦¨à¦¾ à¦†à¦®à¦¿ à¦†à¦œ à¦°à¦¿à¦Ÿà¦¾à¦°à§à¦¨ à¦•à¦°à¦¬à¥¤01819183039', 'à¦–à§à¦¬ à¦­à¦¾à¦²à§‹ à¦•à§à¦¯à¦¾à¦®à§‡à¦°à¦¾ à¦¸à¦¬à¦¾à¦‡ à¦•à¦¿à¦¨à¦¤à§‡ à¦ªà¦¾à¦°à§‡à¦¨ ğŸŒ¹ğŸŒ¹ à¦§à¦¨à§à¦¯à¦¬à¦¾à¦¦ à¦¡à¦¿à¦²à¦¿à¦­à§‡à¦°à¦¿ à¦­à¦¾à¦‡à¦•à§‡ à¦¤à¦¾à¦° à¦•à¦¥à¦¾ à¦…à¦¨à§‡à¦• à¦­à¦¾à¦²à§‹ à¦²à¦¾à¦—à¦²à§‹ğŸŒ¹ğŸŒ¹à¦†à¦®à¦¿ wifi connect à¦•à¦°à¦¤à§‡ à¦ªà¦¾à¦°à¦¤à§‡à¦›à¦¿ à¦¨à¦¾ à¦•à§‡à¦“ à¦ªà¦¾à¦°à¦²à§‡ à¦à¦•à¦Ÿà§ à¦¬à¦²à¦¬à§‡à¦¨ 01902022833 à¦†à¦®à¦¾à¦° à¦‡à¦®à§ à¦†à¦›à§‡', 'OTG ta je kajer Jonno niye silam se kajta Korte pari nai.sudhu mobile change dite parci.amar kache to changer already asei.ai OTG ta sudhu changer lagi nite paren, Thanks for seller,ğŸ˜‰', 'U deserve 5 star â€¦ thank u soo much â€¦ \\n\\nU all can be buy from me on daraz â€¦ visit my store .. \\n\\nhttps://www.daraz.com.bd/shop/barakat-al-madina-shop?liteShop=true&spm=a2a0e.store_hp.top.share&dsource=share&laz_share_info=14651875_100_200_700000844885_14155409_null&laz_token=ac94f48290fcb7d6a4d2c35c6d44e43e', 'vai thank u.sound quality good.product desine good.pray kori apnar buisness aro valo houk.ai budget a ata best.211 thakay ar akta order koraci.asa kori atao best hova.ingshalla.', 'à¦—à§‡à¦à§à¦œà¦¿à¦° à¦•à¦¾à¦ªà¦¡à¦¼à¦Ÿà¦¾ à¦¯à¦¦à¦¿ à¦†à¦°à§‡à¦•à¦Ÿà§ à¦­à¦¾à¦²à§‹ à¦¹à¦¤à§‹ à¦¤à¦¾à¦¹à¦²à§‡ à¦­à¦¾à¦²à§‹ à¦¹à¦¤à§‹ à¦†à¦®à¦¾à¦° à¦¸à¦¬ à¦®à¦¿à¦²à¦¿à¦¯à¦¼à§‡ à¦–à¦°à¦š à§©à§­à§­ à¦Ÿà¦¾à¦•à¦¾ à¦¨à¦¿à¦¯à¦¼à§‡à¦›à§‡ à¦•à¦¿à¦¨à§à¦¤à§ à¦à¦Ÿà¦¾ à¦œà§‡à¦¨à§‡ à¦®à¦¾à¦°à§à¦•à§‡à¦Ÿà§‡ à¦¨à¦¿à¦¤à¦¾à¦® à¦†à¦°à§‹ à¦­à¦¾à¦²à§‹ à¦•à¦¿à¦¨à¦¤à§‡ à¦ªà¦¾à¦°à¦¤à¦¾à¦® à¦†à¦° à¦•à¦¿ à¦²à§‡à¦–à¦¤à¦¾à¦›à¦¿ à¦à¦Ÿà¦¾ à¦†à¦®à¦¾à¦° à¦«à§‹à¦¨ à¦¨à¦¾à¦®à§à¦¬à¦¾à¦°  à§¦à§§à§­à§«à§®à§¯à§¯à§©à§¯à§¦à§©', '1. Navy blue XL T-shirt  à¦†à¦¸à§‡ à¦¨à¦¾à¦‡à¥¤\\n2. White XL T-shirt à¦Ÿà¦¿ à¦¡à¦¾à¦¨ à¦¹à¦¾à¦¤à§‡à¦° à¦‰à¦ªà¦°à§‡à¦° à¦¸à¦¾à¦®à¦¨à§‡à¦° à¦¸à§‡à¦²à¦¾à¦‡ à¦ à¦¿à¦• à¦¨à§‡à¦‡à¥¤ \\nà¦ªà§à¦¯à¦¾à¦•à§‡à¦Ÿà§‡à¦° à¦—à¦¾à¦¯à¦¼à§‡ à¦›à¦¯à¦¼à¦Ÿà¦¿ à¦²à§‡à¦–à¦¾ à¦¥à¦¾à¦•à¦²à§‡à¦“ à¦ªà¦¾à¦à¦šà¦Ÿà¦¿ à¦ªà¦£à§à¦¯ à¦à¦¸à§‡à¦›à§‡à¥¤ à¦…à¦¥à¦š à¦†à¦®à¦¾à¦° à¦›à¦¯à¦¼à¦Ÿà¦¿ à¦ªà¦¨à§à¦¯à§‡à¦° à¦¦à¦¾à¦® à¦ªà¦°à¦¿à¦¶à§‹à¦§ à¦•à¦°à§‡ à¦ªà§à¦¯à¦¾à¦•à§‡à¦Ÿà¦Ÿà¦¿ à¦¨à¦¿à¦¤à§‡ à¦¹à¦¯à¦¼à§‡à¦›à§‡à¥¤\\nà¦à¦–à¦¨ à¦†à¦®à¦¿ à¦à¦Ÿà¦¿ à¦«à§‡à¦°à¦¤ à¦¦à¦¿à¦¤à§‡ à¦šà¦¾à¦‡à¥¤\\nà¦¨à¦¾à¦¹à¦²à§‡ à¦†à¦®à¦¾à¦•à§‡ \\n1.Navy blue XL T-shirt à¦¦à¦¿à¦¤à§‡ à¦¹à¦¬à§‡ à¦à¦¬à¦‚ \\n2. White XL T-shirt change à¦•à¦°à§‡ à¦¦à¦¿à¦¤à§‡ à¦¹à¦¬à§‡à¥¤\\nDARAZ à¦ªà¦¨à§à¦¯à§‡à¦° Quality check à¦¨à¦¾ à¦•à¦°à§‡à¦‡ à¦†à¦®à¦¾à¦•à§‡ à¦ªà¦¨à§à¦¯ à¦¦à¦¿à¦² à¦•à§‡à¦¨à¥¤\\nNavy blue T-shirt à¦¦à§‡à¦–à§‡ à¦…à¦°à§à¦¡à¦¾à¦° à¦•à¦°à§‡à¦›à¦¿à¥¤\\n\\nà¦ªà§à¦°à¦¤à¦¾à¦°à¦¿à¦¤ à¦¹à¦²à¦¾à¦®à¥¤\\nà¦¬à¦¿à¦•à§à¦°à§‡à¦¤à¦¾ à¦«à§‹à¦¨ à¦§à¦°à§‡à¦¨ à¦¨à¦¿à¥¤\\nà¦†à¦®à¦¾à¦° à¦®à§‹à¦¬à¦¾à¦‡à¦² à¦¨à¦‚ 01612621862 /\\n01912217998.', 'This is excellent I recommend it for everyone one itâ€™s 10000000000000000000000000000000000000 0000000000000000000000000000000000000 0000000000000000000000000000000000000 0000000000000000000000000000000000000 real not replica or fake itâ€™s 10000000000000000000000000000000000000 0000000000000000000000000000000000000 0000000000000000000000000000000000000 0000000000000000000000000000000000000 percent real', 'it was a great pokemon card folder 100000000000 million', 'à¦–à§à¦¬ à¦­à¦¾à¦²à§‹ à¦à¦¬à¦‚ à¦¸à§à¦¨à§à¦¦à¦° à¦à¦•à¦Ÿà¦¾ à¦ªà§à¦°à§‹à¦¡à¦¾à¦•à§à¦Ÿ \\nà¦‡à¦¨à§à¦Ÿà§‡à¦• à¦®à¦¾à¦² à¦ªà¦¾à¦‡à¦›à¦¿ \\u200cà¥¤à§§à§¦à§¦/à§§à§¦à§¦à§¦à§¦à§¦à§¦à§¦à§¯', 'à¦›à¦¬à¦¿à¦¤à§‡ à¦¯à§‡à¦®à¦¨ à¦¦à§‡à¦–à¦¾ à¦¯à¦¾à¦šà§à¦›à§‡ à¦¬à¦¾à¦¸à§à¦¤à¦¬à§‡ à¦ªà§à¦°à§‹à¦¡à¦¾à¦•à§à¦Ÿà¦Ÿà¦¿ à¦¤à§‡à¦®à¦¨ à¦¨à§Ÿà¥¤à¦à¦° à¦«à¦¾à¦• à¦¦à¦¿à§Ÿà§‡ à¦¬à¦¾à¦šà§à¦šà¦¾ à¦¯à§‡ à¦•à§‹à¦¨ à¦¸à¦®à§Ÿ à¦ªà§œà§‡ à¦¯à§‡à¦¤à§‡ à¦ªà¦¾à¦°à§‡à¥¤à¦à¦®à¦¨ à¦œà¦¿à¦¨à¦¿à¦¸ à¦†à¦®à¦¿ à¦šà¦¾à¦‡à¦¨à¦¿à¥¤à¦¸à§‡à¦²à¦¾à¦° à¦†à¦®à¦¾à¦•à§‡ à¦¦à§‹à¦²à¦¨à¦¾à¦Ÿà¦¿ à¦ªà¦°à¦¿à¦¬à¦°à§à¦¤à¦¨ à¦•à¦°à§‡ à¦¦à§‡à¦¬à§‡à¦¨à¥¤à¦…à¦¤à¦¿à¦°à¦¿à¦•à§à¦¤ à¦ªà§‡à¦®à§‡à¦¨à§à¦Ÿ à¦¯à¦¾ à¦†à¦¸à¦¬à§‡ à¦¦à¦¿à§Ÿà§‡ à¦¦à§‡à¦¬à§‹à¥¤à¦¬\\u200dà§à¦¯à¦¬à¦¸à¦¾à§Ÿà¦¿à¦• à¦•à¦¾à¦°à¦£à§‡ à¦›à¦¬à¦¿à¦Ÿà¦¿ à¦¶à§‡à§Ÿà¦¾à¦° à¦•à¦°à¦¿à¦¨à¦¿à¥¤à¦§à¦¨\\u200dà§à¦¯à¦¬à¦¾à¦¦à¥¤à¦«à§‹à¦¨ 01766620848', 'atto baje.ai 1st daraz thaika kichu kinna mejaj kharap hoilo.baccha ra e boshte vhoy paccha.r aigula ki dori dea desa.thur.1dom baze.', 'khub valo lagteche. product ti peye...product is good....thanks daraz.com ke....', 'à¦†à¦²à¦¹à¦¾à¦®à¦¦à§à¦²à¦¿à¦²à§à¦²à¦¾à¦¹ à¦†à¦²à¦¹à¦¾à¦®à¦¦à§à¦²à¦¿à¦²à§à¦²à¦¾à¦¹ à¦ªà§à¦°à§‹à¦¡à¦¾à¦•à§à¦Ÿ à¦…à¦¨à§‡à¦• à¦…à¦¨à§‡à¦• à¦­à¦¾à¦²à§‹ à¦†à¦° à¦›à§‡à¦²à¦¾à¦° à¦à¦° à¦•à¦¥à¦¾ à¦•à¦¿ à¦¬à¦²à¦¬à§‹ à¦¸à§‡ à¦†à¦®à¦¾à¦•à§‡ à¦…à¦¨à§‡à¦• à¦¸à¦¾à¦¹à¦¾à¦¯à§à¦¯ à¦•à¦°à¦›à§‡ à¦ªà§à¦°à§‹à¦¡à¦¾à¦•à§à¦Ÿ à¦­à¦¾à¦²à§‹ à¦ªà§‡à¦¯à¦¼à§‡à¦›à¦¿ à¦†à¦° à¦ªà§à¦¯à¦¾à¦•à§‡à¦œà¦¿à¦‚ à¦à¦° à¦•à¦¥à¦¾ à¦•à¦¿ à¦¬à¦²à¦¬ à§§à§¦à§¦ à¦¤à§‡ à§§à§¦à§¦ à¦†à¦®à¦¿ à¦…à¦¨à§‡à¦• à¦–à§à¦¶à¦¿  à¦¸à§à¦§à§ à¦¸à¦¾à¦¥à§‡ à¦«à§à¦°à¦¿ à¦†à¦‡à¦Ÿà§‡à¦®à¦Ÿà¦¾ à¦ªà¦¾à¦‡ à¦¨à¦¾à¦‡ à¦à¦¬à¦‚ à¦¸à¦¾à¦‡à¦œà¦Ÿà¦¾ à¦…à¦¨à§‡à¦• à¦›à§‹à¦Ÿ à¦›à¦¬à¦¿à¦¤à§‡ à¦¯à§‡à¦°à¦•à¦® à¦¦à§‡à¦–à¦¾ à¦¯à¦¾à¦¯à¦¼ à¦¸à§‡à¦°à¦•à¦® à¦¨à¦¾  à¦†à¦°à§‹ à¦¤à¦¥à§à¦¯ à¦œà¦¾à¦¨à¦¤à§‡ à¦à¦‡ à¦¨à¦¾à¦®à§à¦¬à¦¾à¦°à§‡ à¦¯à§‹à¦—à¦¾à¦¯à§‹à¦— à¦•à¦°à§à¦¨ 01307464358', 'DEX-BDN-0054380949\\njemon ta caisi thik tmn tai paici alhamdulillah \\nseller vaiya ta onnnnnk valo Ami r amr apu er aga o onk kicu anci daraz thike alhamdulillah kokhono thoki nai r seller vaiya ta Oni sob smy ase onr behaviour a onk ta impresse Amra daraz er proti. Shahnawaz maybe nam vaiya tar tnQ vaiya r tnQ daraz.', \"That's really good and too much pretty ğŸ’\\nhttps://youtube.com/shorts/2cAbgzPnpWs?feature=share\", 'à¦¬à§à¦¯à¦¾à¦— à¦Ÿà¦¾ à¦ªà§à¦°à¦¥à¦®à§‡à¦‡ à¦à¦•à¦Ÿà§ à¦ªà§à¦°à¦¨à§‹ à¦®à¦¨à§‡ à¦¹à¦‡à¦›à§‡, à¦ªà§à¦¯à¦¾à¦•à§‡à¦œà¦¿à¦‚ à¦Ÿà¦¾ à¦­à¦¾à¦²à§‹ à¦¨à¦¾, just à§¨ à¦Ÿà¦¾ à¦ªà¦²à¦¿à¦¥à¦¿à¦¨ à¦à¦° à¦¬à§à¦¯à¦¾à¦—à¥¤ à¦¤à¦¾à¦“ à¦•à¦¿à¦›à§ à¦®à¦¨à§‡ à¦•à¦°à§ à¦¨à¦¾à¦‡à¥¤ à¦à¦•à¦¦à¦® à§§ à¦®à¦¾à¦¸ à¦ªà¦°à§‡ à§¬ à¦œà§à¦²à¦¾à¦‡ à¦ªà§‡à§Ÿà§‡à¦›à¦¿à¥¤  à¦…à¦¨à§à¦¯à§‡à¦• excited chilam bag à¦Ÿà¦¾à¦° à¦œà¦¨à§à¦¯.... à¦†à¦œà¦•à§‡ à§ª à¦¦à¦¿à¦¨ à¦¹à¦²à§‹ à¦¬à§à¦¯à¦¾à¦—à¦Ÿà¦¾ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦•à¦°à¦¤à§‡à¦›à¦¿, à¦†à¦¾à¦° à¦ à¦…à¦¬à¦¸à§à¦¥à¦¾à¥¤ à¦à¦•à¦¦à¦® à¦¬à¦›à¦° à¦ªà§à¦°à¦¨à§‹ à¦®à¦¨à§‡ à¦¹à¦šà§à¦›à§‡, à¦•à¦¾à¦²à§‹ à¦°à¦™ à¦¤à§‹ à¦¯à¦¾à§Ÿ à¦¯à¦¾à§Ÿà¥¤ à¦¸à¦¬à¦¾à¦° à¦à¦¤à§à¦¤à§‹ à¦­à¦¾à¦²à§‹ à¦°à¦¿à¦­à¦¿à¦“ à¦¦à§‡à¦–à§‡ à¦¨à¦¿à¦¶à§à¦šà¦¿à¦¤ à¦›à¦¿à¦²à¦¾à¦® Best à¦Ÿà¦¾à¦‡ à¦¨à¦¿à¦šà§à¦›à¦¿à¥¤ But for my disappointment my desired pencil bag is worsened.  à¦†à¦¬à¦¾à¦°à§‹ à¦¬à¦²à¦›à¦¿, à¦…à¦¨à§‡à¦• à¦¶à¦– à¦•à¦°à§‡ à¦Ÿà¦¾à¦•à¦¾ à¦œà¦®à¦¿à§Ÿà§‡ à¦•à¦¿à¦¨à§‡à¦›à¦¿, à¦à¦®à¦¨ Product à¦ªà¦¾à¦¬à§‹ à¦­à¦¾à¦¬à¦¿à¦¨à¦¿643661745238908', 'à¦œà¦¿à¦¨à¦¿à¦¸à¦Ÿà¦¾ à¦­à¦¾à¦²à¦‡ à¦†à¦®à¦¾à¦•à§‡ à¦¬à§‡à¦¶ à¦­à¦¾à¦²à§‹ à¦²à¦¾à¦—à¦›à§‡ à§¦à§§à§­ à§¬à§¨à§¯à§©à§«à§¦à§ªà§§', 'Sunglasses are very good. However, it is too late to get it. Thanks to Seller Man.\\n\\nà¦†à¦ªà¦¨à§‡à¦°à¦¾ à¦¯à¦¾à¦°à¦¾ à¦¨à¦¿à¦¤à§‡ à¦šà¦¾à¦¨, à¦¨à¦¿à¦¤à§‡ à¦ªà¦¾à¦°à§‡à¦¨à¥¤ à¦†à¦°à§‹ à¦•à¦¿à¦›à§ à¦œà¦¾à¦¨à¦¤à§‡ à¦šà¦¾à¦‡à¦²à§‡ à¥¤fb...www.facebook.com/s.a.sumon.07', 'ato olpo dam a onek sundor akti product peyesi.Ai Jonno daraz k onek dhonnobad.', 'à¦–à§à¦¬à¦‡ à¦®à¦¾à¦¨à¦¸à¦®à§à¦®à¦¤ à¦ªà§à¦°à§‹à¦¡à¦¾à¦•à§à¦Ÿ,à¦…à¦°à§à¦¡à¦¾à¦° à¦“ à¦ªà§à¦°à¦¾à¦ªà§à¦¤à¦¿ à¦•à§‹à¦¨ à¦¤à¦«à¦¾à§ à¦¨à§‡à¦‡ à¥¤à¦§à¦¨à§à¦¯à¦¬à¦¾à¦¦ à¦¸à§‡à¦²à¦¾à¦° à¦“ à¦¦à¦¾à¦°à¦¾à¦œ à¦•à§‡à¥¤à¦à¦‡ à¦§à¦°à¦¨à§‡à¦° à¦¬à¦¿à¦•à§à¦°à§‡à¦¤à¦¾ à¦¦à§‡à¦° à¦¦à¦¾à¦°à¦¾à¦œ à¦‰à§à¦¸à¦¾à¦¹à¦¿à¦¤ à¦•à¦°à§‡ à¦¬à¦¿à¦¶à§‡à¦· à¦°à§‡à¦Ÿà¦¿à¦‚ à¦¦à§‡à¦“à§Ÿà¦¾ à¦‰à¦šà¦¿à§à¥¤à¦…à¦¸à¦®à§à¦­à¦¬ à¦­à¦¾à¦² à¦à¦•à¦Ÿà¦¿ à¦ªà§à¦°à§‹à¦¡à¦¾à¦•à§à¦Ÿ à¦à¦Ÿà¦¾à¦° à¦ªà§à¦°à¦¶à¦‚à¦¸à¦¾ à¦¨à¦¾ à¦•à¦°à§‡ à¦ªà¦¾à¦°à¦²à¦¾à¦® à¦¨à¦¾ à¦†à¦œ à¦…à¦¬à§à¦¦à¦¿ à¦¦à¦¾à¦°à¦¾à¦¸ à¦®à¦¹à¦² à¦¥à§‡à¦•à§‡ à¦…à¦¸à¦‚à¦–à§à¦¯ à¦ªà§à¦°à¦¡à¦¾à¦•à§à¦Ÿ à¦à¦¨à§‡à¦›à¦¿ à¦à¦•à¦Ÿà¦¾à¦“ à¦°à¦¿à¦­à¦¿à¦‰ à¦¦à§‡à¦‡à¦¨à¦¿ à¦•à¦¿à¦¨à§à¦¤à§ à¦à¦Ÿà¦¾ à¦¨à¦¾ à¦¦à¦¿à¦¯à¦¼à§‡ à¦ªà¦¾à¦°à¦²à¦¾à¦® à¦¨à¦¾ à¦§à¦¨à§à¦¯à¦¬à¦¾à¦¦ à¦¸à§‡à¦²à¦¾à¦° à¦•à§‡ Alhamdulillah Jahanara Enterprise always best....\\nProduct 10000% original and 100000% ok...', \"I bought this tv in October 2022. But after I Factory Data Reset it it's colors are distorted. Please help me. H & Rahman Co nilmonisutradhar52 gmail.com\", 'à¦¸à¦¾à¦‰à¦¨à§à¦¡ à¦à¦° à¦¸à¦®à¦¸à§à¦¯à¦¾ à¦à¦¬à¦‚ à¦à¦®à¦¨ à¦¹à¦¯à¦¼à§‡ à¦†à¦›à§‡? \\nà¦•à¦¿ à¦•à¦°à¦¬à§‹??\\n01717413274', 'overall packing bhalo chelo.ai price Aya daraz e detay parbe kisu din use ar por ar bhalo koray details bola jabe', 'Alhamdulillah.In 11.11 campaign it cost me 54434 taka,cod, ordered on 12.11.22.In last 30 days I have done lots of homework  to buy one 55\" tv. After considering everything I must say at 54k people should buy this with out hesitation believing Xiaomi will provide good after sales service. the only competitor is Haier ,are providing 1.5gb and 8gb.Even people can consider it with higher price because of world cup and official product.', '1kg alu er moddhe 450gm alui pocha chilo.Alu Katar pore bujha giyeche.Bahir diye alu ekebare fresh.Loss Hoye gelo.Shop er cheye kom price dekhe onekei daraz e oder dey But kom price hoyar karon ki? Kew jante chayna. Healthy khan ar healthy thakun.Kom diye niye lav er cheye loss beshi.', 'à¦¦à¦¾à¦°à¦¾à¦œ à¦¥à§‡à¦•à§‡ à¦®à¦¾à¦¤à§à¦° à¦¨à¦¾à¦® à¦®à§‚à¦² à¦¦à¦¿à§Ÿà§‡ à¦ªà§à¦°à§‹à¦¡à¦¾à¦•à§à¦Ÿ à¦•à¦¿à¦¨à¦¤à§‡ à¦ªà§‡à¦°à§‡ à¦–à§à¦¬à¦‡ à¦­à¦¾à¦²à§‹ à¦²à¦¾à¦—à¦›à§‡ à¦¸à¦¬à¦¾à¦‡ à¦¦à¦¾à¦°à¦¾à¦œ à¦¥à§‡à¦•à§‡ à¦•à§‡à¦¨à¦¾ à¦•à¦¾à¦Ÿà¦¾ à¦•à¦°à§à¦¨à¥¤\\nà¦ªà§à¦°à§Ÿà§‹à¦œà¦¨ à¦ à¦•à¦² à¦¦à¦¿à§Ÿà§‡ à¦¸à¦¾à¦¹à¦¾à¦¯à§à¦¯ à¦¨à¦¿à¦¤à§‡ à¦ªà¦¾à¦°à§‡à¦¨ à¦†à¦®à¦¾à¦° à¦¥à§‡à¦•à§‡ à§¦à§§à§¬à§ªà§§à§¦à§­à§§à§«à§«à§­', 'à¦¬à¦¾à¦œà§‡à¦Ÿ à¦…à¦¨à§à¦¯à¦¾à¦¯à¦¼à§€ à¦«à§à¦¯à¦¾à¦¨à¦Ÿà¦¿à¦° à¦–à§à¦¬ à¦­à¦¾à¦²à§‹à¥¤  à¦«à§à¦¯à¦¾à¦¨à¦Ÿà¦¿à¦° à¦°à¦¿à¦­à¦¿à¦‰ à¦¦à§‡à¦–à¦¤à§‡ à¦šà¦¾à¦‡à¦²à§‡ à¦¨à¦¿à¦šà§‡ à¦•à§à¦²à¦¿à¦• à¦•à¦°à§‡ à¦¦à§‡à¦–à¦¤à§‡ à¦ªà¦¾à¦°à§‡à¦¨ğŸ‘‡ğŸ‘‡\\nhttps://youtube.com/shorts/BgiQ81IZmhI?si=FBQ8GEwICdhRZ7EM']\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4cf91db0552df860"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_dedup_emoji_contact = df_dedup_emoji.loc[~mask].reset_index(drop=True)\n",
    "df_dedup_emoji_contact.to_csv(DATA_PROCESSED/ \"dataset_dedup_emoji_contact.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"\\nAfter removal of dedup, emoji, contact info, order id:\", len(df_dedup_emoji_contact))\n"
   ],
   "id": "23ea03694d9b2e9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T11:18:47.440018Z",
     "start_time": "2025-12-13T11:18:39.741768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------------- ABSA suitability filter (remove generic / too-short / non-aspect reviews) ----------------\n",
    "# Goal: keep more ABSA-friendly reviews (multi-aspect or compound/contrast), remove generic ones like\n",
    "# \"Recommend\", \"Good\", \"Awesome\", \"à¦­à¦¾à¦²à§‹\", \"very good product\", etc.\n",
    "\n",
    "ABSA_FILTER_LEVEL = \"strict\"  # \"strict\" (recommended) or \"balanced\"\n",
    "OUT_ABSA_PATH = DATA_PROCESSED / f\"dataset_absa_ready_{ABSA_FILTER_LEVEL}.csv\"\n",
    "\n",
    "# --- helpers ---\n",
    "SPACE_RE = re.compile(r\"\\s+\")\n",
    "PUNCT_KEEP_CLAUSE_SEP_RE = re.compile(r\"[^\\w\\s\\u0980-\\u09FF,;à¥¤!?]\")  # keep bn letters + common clause separators\n",
    "\n",
    "def _strip_emoji(s: str) -> str:\n",
    "    # uses emoji module if available (already imported above)\n",
    "    try:\n",
    "        return emoji.replace_emoji(s, replace=\" \")\n",
    "    except Exception:\n",
    "        return s\n",
    "\n",
    "def normalize_text(s: str) -> str:\n",
    "    if not isinstance(s, str):\n",
    "        return \"\"\n",
    "    s = html.unescape(s)\n",
    "    s = unicodedata.normalize(\"NFKC\", s)\n",
    "    s = _strip_emoji(s)\n",
    "    s = s.lower()\n",
    "    s = PUNCT_KEEP_CLAUSE_SEP_RE.sub(\" \", s)\n",
    "    s = SPACE_RE.sub(\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "# Generic phrases/words (you can extend this list)\n",
    "GENERIC_PHRASES = {\n",
    "    \"recommend\", \"recommended\", \"good\", \"very good\", \"nice\", \"awesome\", \"perfect\", \"fine\",\n",
    "    \"thanks\", \"thank you\", \"just wow\", \"wow\", \"gd\", \"too good\", \"not bad\",\n",
    "    \"good product\", \"very good product\", \"good quality product\", \"good stuff\", \"looks great\",\n",
    "    \"valo\", \"bhalo\", \"khub valo\", \"khub bhalo\", \"valo na\", \"bhalo na\",\n",
    "    \"à¦­à¦¾à¦²à§‹\", \"à¦­à¦¾à¦²\", \"à¦–à§à¦¬ à¦­à¦¾à¦²à§‹\", \"à¦–à§à¦¬ à¦­à¦¾à¦²\", \"à¦§à¦¨à§à¦¯à¦¬à¦¾à¦¦\", \"à¦…à¦¸à¦¾à¦§à¦¾à¦°à¦£\", \"à¦¦à¦¾à¦°à§à¦¨\", \"à¦šà¦®à§à¦•à¦¾à¦°\", \"à¦œà§‹à¦¸\",\n",
    "    \"à¦®à§‹à¦Ÿà¦¾à¦®à§à¦Ÿà¦¿\", \"à¦®à¦¨à§à¦¦ à¦¨à¦¾\", \"à¦­à¦¾à¦²à§‹ à¦¨à¦¾\", \"à¦–à¦¾à¦°à¦¾à¦ª\"\n",
    "}\n",
    "\n",
    "GENERIC_TOKENS = {\n",
    "    # English\n",
    "    \"good\", \"great\", \"nice\", \"awesome\", \"perfect\", \"fine\", \"excellent\", \"amazing\", \"wow\",\n",
    "    \"recommend\", \"recommended\", \"thanks\", \"thank\", \"satisfied\", \"love\", \"happy\", \"best\", \"ok\", \"okay\", \"gd\",\n",
    "    \"product\", \"quality\", \"stuff\", \"looks\",\n",
    "    # Romanized Bangla\n",
    "    \"valo\", \"bhalo\", \"khub\", \"onek\", \"sundor\", \"joss\", \"darun\", \"motamoti\", \"baje\",\n",
    "    # Bangla\n",
    "    \"à¦­à¦¾à¦²à§‹\", \"à¦­à¦¾à¦²\", \"à¦–à§à¦¬\", \"à¦…à¦¸à¦¾à¦§à¦¾à¦°à¦£\", \"à¦¦à¦¾à¦°à§à¦¨\", \"à¦šà¦®à§à¦•à¦¾à¦°\", \"à¦§à¦¨à§à¦¯à¦¬à¦¾à¦¦\", \"à¦œà§‹à¦¸\", \"à¦¸à§à¦¨à§à¦¦à¦°\", \"à¦®à§‹à¦Ÿà¦¾à¦®à§à¦Ÿà¦¿\", \"à¦–à¦¾à¦°à¦¾à¦ª\", \"à¦¬à¦¾à¦œà§‡\", \"à¦®à¦¨à§à¦¦\"\n",
    "}\n",
    "\n",
    "STOPWORDS = set(\"\"\"\n",
    " a an the is are was were am be been being to of in on for at by with and or but if then so as from this that it its\n",
    " i we you he she they my our your their me us him her them\n",
    " à¦†à¦®à¦¿ à¦†à¦®à¦°à¦¾ à¦¤à§à¦®à¦¿ à¦¤à§‹à¦®à¦°à¦¾ à¦¸à§‡ à¦¤à¦¾à¦°à¦¾ à¦à¦‡ à¦“à¦‡ à¦¸à§‡à¦Ÿà¦¾ à¦à¦Ÿà¦¾ à¦“à¦Ÿà¦¾ à¦à¦¬à¦‚ à¦†à¦° à¦•à¦¿à¦¨à§à¦¤à§ à¦¤à§‹ à¦¤à¦¬à§‡ à¦¯à¦¦à¦¿ à¦¤à¦¾à¦¹à¦²à§‡ à¦¥à§‡à¦•à§‡ à¦œà¦¨à§à¦¯ à¦¸à¦¾à¦¥à§‡ à¦‰à¦ªà¦° à¦®à¦§à§à¦¯à§‡ à¦¦à¦¿à§Ÿà§‡ à¦¯à§‡ à¦¨à¦¾ à¦–à§à¦¬ à¦…à¦¨à§‡à¦• à¦à¦•à¦¦à¦® à¦¶à§à¦§à§\n",
    " ami amra tumi tora apni apnara she tara eta eita oita ar ebong kintu tobe jodio na khub onek sudhu\n",
    "\"\"\".split())\n",
    "\n",
    "# Aspect lexicon: categories -> keywords (English + Bangla + common Banglish)\n",
    "# Aspect lexicon: taxonomy-aligned categories -> keywords (English + Bangla + common Banglish)\n",
    "# NOTE: this is a lightweight keyword lexicon used ONLY for filtering ABSA-suitable reviews.\n",
    "# It is NOT the final taxonomy mapping for ABSA labeling.\n",
    "ASPECTS = {\n",
    "    # -------- Global aspects --------\n",
    "    \"DELIVERY\": [\n",
    "        \"delivery\", \"delivered\", \"deliver\", \"shipping\", \"ship\", \"courier\", \"rider\", \"dispatch\", \"arrival\", \"arrive\", \"received\", \"receive\",\n",
    "        \"on time\", \"same day\", \"next day\", \"late\", \"delay\", \"delayed\", \"slow\", \"fast\",\n",
    "        \"à¦¡à§‡à¦²à¦¿à¦­à¦¾à¦°à¦¿\", \"à¦¡à§‡à¦²à¦¿à¦­à¦¾à¦°à¦¿ à¦®à§à¦¯à¦¾à¦¨\", \"à¦•à§à¦°à¦¿à§Ÿà¦¾à¦°\", \"à¦•à§à¦°à¦¿à¦¯à¦¼à¦¾à¦°\", \"à¦•à§à¦°à¦¿à§Ÿà¦¾à¦° à¦¸à¦¾à¦°à§à¦­à¦¿à¦¸\", \"à¦°à¦¾à¦‡à¦¡à¦¾à¦°\", \"à¦¡à¦¿à¦¸à¦ªà§à¦¯à¦¾à¦š\", \"à¦ªà¦¾à¦ à¦¾à¦¨à§‹\", \"à¦ªà¦¾à¦ à¦¿à§Ÿà§‡à¦›à§‡\", \"à¦ªà§Œà¦à¦›\", \"à¦ªà§Œà¦à¦›à§‡à¦›à§‡\",\n",
    "        \"à¦¸à¦®à§Ÿ\", \"à¦¸à¦®à¦¯à¦¼\", \"à¦¸à¦®à§Ÿà¦®à¦¤à§‹\", \"à¦¸à¦®à¦¯à¦¼à¦®à¦¤à§‹\", \"à¦¦à§‡à¦°à¦¿\", \"à¦²à§‡à¦Ÿ\", \"à¦¦à§à¦°à§à¦¤\", \"à¦§à§€à¦°à§‡\"\n",
    "    ],\n",
    "    \"PACKAGING\": [\n",
    "        \"packaging\", \"package\", \"packed\", \"pack\", \"box\", \"carton\", \"wrapper\", \"seal\", \"sealed\", \"bubble wrap\", \"tape\",\n",
    "        \"protection\", \"protect\", \"safe\", \"damaged\", \"broken\", \"dent\", \"crushed\", \"leak\", \"leakage\", \"torn\",\n",
    "        \"pouch\", \"poly\", \"polythene\",\n",
    "        \"à¦ªà§à¦¯à¦¾à¦•à§‡à¦œà¦¿à¦‚\", \"à¦ªà§à¦¯à¦¾à¦•à§‡à¦Ÿ\", \"à¦¬à¦•à§à¦¸\", \"à¦•à¦¾à¦°à§à¦Ÿà¦¨\", \"à¦°â€Œà§à¦¯à¦¾à¦ª\", \"à¦°â€à§à¦¯à¦¾à¦ª\", \"à¦®à§‹à§œà¦•\", \"à¦®à§‹à¦¡à¦¼à¦•\", \"à¦¸à¦¿à¦²\", \"à¦¸à¦¿à¦²à¦—à¦¾à¦²à¦¾\", \"à¦Ÿà§‡à¦ª\",\n",
    "        \"à¦¨à¦¿à¦°à¦¾à¦ªà¦¦\", \"à¦ªà§à¦°à¦Ÿà§‡à¦•à¦¶à¦¨\", \"à¦•à§à¦·à¦¤à¦¿à¦—à§à¦°à¦¸à§à¦¤\", \"à¦¨à¦·à§à¦Ÿ\", \"à¦­à¦¾à¦™à¦¾\", \"à¦¡à§‡à¦¨à§à¦Ÿ\", \"à¦šà¦¿à¦ª\", \"à¦šà¦¾à¦ªà¦¾\", \"à¦«à¦¾à¦Ÿà¦¾\", \"à¦²à¦¿à¦•\", \"à¦›à¦¿à¦¦à§à¦°\"\n",
    "    ],\n",
    "    \"PRICE\": [\n",
    "        \"price\", \"pricing\", \"cost\", \"value\", \"worth\", \"value for money\", \"affordable\", \"cheap\", \"cheaper\", \"expensive\", \"overpriced\",\n",
    "        \"budget\", \"discount\", \"offer\", \"deal\", \"sale\", \"taka\", \"tk\", \"à§³\",\n",
    "        \"à¦¦à¦¾à¦®\", \"à¦®à§‚à¦²à§à¦¯\", \"à¦Ÿà¦¾à¦•à¦¾\", \"à¦¸à¦¸à§à¦¤à¦¾\", \"à¦•à¦®à¦¦à¦¾à¦®\", \"à¦¬à¦¾à¦œà§‡à¦Ÿ\", \"à¦¡à¦¿à¦¸à¦•à¦¾à¦‰à¦¨à§à¦Ÿ\", \"à¦›à¦¾à§œ\", \"à¦…à¦«à¦¾à¦°\", \"à¦¬à§‡à¦¶à¦¿ à¦¦à¦¾à¦®\", \"à¦¦à¦¾à¦® à¦¬à§‡à¦¶à¦¿\"\n",
    "    ],\n",
    "    \"SERVICE\": [\n",
    "        \"service\", \"seller\", \"shop\", \"store\", \"support\", \"help\", \"customer care\", \"after sales\", \"response\", \"reply\", \"communication\",\n",
    "        \"behavior\", \"behaviour\", \"polite\", \"rude\", \"helpful\",\n",
    "        \"return\", \"refund\", \"replacement\", \"exchange\", \"complain\", \"complaint\",\n",
    "        \"warranty\", \"guarantee\", \"guaranty\",\n",
    "        \"à¦¸à¦¾à¦°à§à¦­à¦¿à¦¸\", \"à¦¸à§‡à¦²à¦¾à¦°\", \"à¦¬à¦¿à¦•à§à¦°à§‡à¦¤à¦¾\", \"à¦¶à¦ª\", \"à¦¸à§à¦Ÿà§‹à¦°\", \"à¦¸à¦¾à¦ªà§‹à¦°à§à¦Ÿ\", \"à¦¹à§‡à¦²à§à¦ª\", \"à¦•à¦¾à¦¸à§à¦Ÿà¦®à¦¾à¦° à¦•à§‡à§Ÿà¦¾à¦°\", \"à¦•à¦¾à¦¸à§à¦Ÿà¦®à¦¾à¦°\", \"à¦°à§‡à¦¸à¦ªà¦¨à§à¦¸\", \"à¦°à¦¿à¦ªà§à¦²à¦¾à¦‡\",\n",
    "        \"à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦°\", \"à¦†à¦šà¦°à¦£\", \"à¦­à¦¦à§à¦°\", \"à¦°à§‚à§\", \"à¦–à¦¾à¦°à¦¾à¦ª à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦°\",\n",
    "        \"à¦°à¦¿à¦Ÿà¦¾à¦°à§à¦¨\", \"à¦°à¦¿à¦«à¦¾à¦¨à§à¦¡\", \"à¦°à¦¿à¦ªà§à¦²à§‡à¦¸\", \"à¦šà§‡à¦à§à¦œ\", \"à¦à¦•à§à¦¸à¦šà§‡à¦à§à¦œ\", \"à¦…à¦­à¦¿à¦¯à§‹à¦—\",\n",
    "        \"à¦“à§Ÿà¦¾à¦°à§‡à¦¨à§à¦Ÿà¦¿\", \"à¦“à¦¯à¦¼à¦¾à¦°à§‡à¦¨à§à¦Ÿà¦¿\", \"à¦—à§à¦¯à¦¾à¦°à¦¾à¦¨à§à¦Ÿà¦¿\"\n",
    "    ],\n",
    "\n",
    "    # -------- Electronics & Gadgets --------\n",
    "    \"PERFORMANCE\": [\n",
    "        \"performance\", \"speed\", \"smooth\", \"lag\", \"slow\", \"hang\", \"freeze\", \"responsive\",\n",
    "        \"heating\", \"overheat\", \"temperature\", \"gaming\", \"multitask\", \"processor\", \"chipset\",\n",
    "        \"à¦ªà¦¾à¦°à¦«à¦°à¦®à§à¦¯à¦¾à¦¨à§à¦¸\", \"à¦¸à§à¦ªà¦¿à¦¡\", \"à¦¸à§à¦®à§à¦¥\", \"à¦²à§à¦¯à¦¾à¦—\", \"à¦¸à§à¦²à§‹\", \"à¦¹à§à¦¯à¦¾à¦‚\", \"à¦«à§à¦°à¦¿à¦œ\", \"à¦°à§‡à¦¸à¦ªà¦¨à§à¦¸à¦¿à¦­\",\n",
    "        \"à¦—à¦°à¦®\", \"à¦¹à¦¿à¦Ÿà¦¿à¦‚\", \"à¦“à¦­à¦¾à¦°à¦¹à¦¿à¦Ÿ\", \"à¦Ÿà§‡à¦®à§à¦ªà¦¾à¦°à§‡à¦šà¦¾à¦°\", \"à¦—à§‡à¦®à¦¿à¦‚\", \"à¦ªà§à¦°à¦¸à§‡à¦¸à¦°\"\n",
    "    ],\n",
    "    \"BATTERY\": [\n",
    "        \"battery\", \"backup\", \"charge\", \"charging\", \"fast charging\", \"slow charging\", \"charger\", \"power\", \"drain\", \"standby\",\n",
    "        \"à¦¬à§à¦¯à¦¾à¦Ÿà¦¾à¦°à¦¿\", \"à¦¬à§à¦¯à¦¾à¦•à¦†à¦ª\", \"à¦šà¦¾à¦°à§à¦œ\", \"à¦šà¦¾à¦°à§à¦œà¦¿à¦‚\", \"à¦«à¦¾à¦¸à§à¦Ÿ à¦šà¦¾à¦°à§à¦œ\", \"à¦šà¦¾à¦°à§à¦œà¦¾à¦°\", \"à¦ªà¦¾à¦“à§Ÿà¦¾à¦°\", \"à¦¡à§à¦°à§‡à¦¨\", \"à¦šà¦¾à¦°à§à¦œ à¦§à¦°à§‡\"\n",
    "    ],\n",
    "    \"DISPLAY\": [\n",
    "        \"display\", \"screen\", \"touchscreen\", \"touch\", \"lcd\", \"led\", \"amoled\", \"oled\",\n",
    "        \"resolution\", \"brightness\", \"dim\", \"color\", \"colour\", \"refresh\", \"hz\", \"viewing angle\",\n",
    "        \"pixel\", \"dead pixel\", \"scratch\",\n",
    "        \"à¦¡à¦¿à¦¸à¦ªà§à¦²à§‡\", \"à¦¸à§à¦•à§à¦°à¦¿à¦¨\", \"à¦Ÿà¦¾à¦š\", \"à¦Ÿà¦¾à¦šà¦¸à§à¦•à§à¦°à¦¿à¦¨\", \"à¦à¦²à¦¸à¦¿à¦¡à¦¿\", \"à¦à¦²à¦‡à¦¡à¦¿\", \"à¦…à§à¦¯à¦¾à¦®à§‹à¦²à§‡à¦¡\", \"à¦“à¦²à§‡à¦¡\",\n",
    "        \"à¦°à§‡à¦œà§‹à¦²à¦¿à¦‰à¦¶à¦¨\", \"à¦¬à§à¦°à¦¾à¦‡à¦Ÿà¦¨à§‡à¦¸\", \"à¦¡à¦¿à¦®\", \"à¦•à¦¾à¦²à¦¾à¦°\", \"à¦°à¦¿à¦«à§à¦°à§‡à¦¶\", \"à¦­à¦¿à¦‰ à¦…à§à¦¯à¦¾à¦™à§à¦—à§‡à¦²\",\n",
    "        \"à¦ªà¦¿à¦•à§à¦¸à§‡à¦²\", \"à¦¡à§‡à¦¡ à¦ªà¦¿à¦•à§à¦¸à§‡à¦²\", \"à¦¸à§à¦•à§à¦°à§à¦¯à¦¾à¦š\"\n",
    "    ],\n",
    "    \"CAMERA\": [\n",
    "        \"camera\", \"photo\", \"picture\", \"image\", \"video\", \"selfie\", \"portrait\", \"night mode\", \"zoom\", \"focus\", \"stabilization\",\n",
    "        \"photo quality\", \"video quality\",\n",
    "        \"à¦•à§à¦¯à¦¾à¦®à§‡à¦°à¦¾\", \"à¦›à¦¬à¦¿\", \"à¦«à¦Ÿà§‹\", \"à¦ªà¦¿à¦•à¦šà¦¾à¦°\", \"à¦‡à¦®à§‡à¦œ\", \"à¦­à¦¿à¦¡à¦¿à¦“\", \"à¦¸à§‡à¦²à¦«à¦¿\", \"à¦ªà§‹à¦°à§à¦Ÿà§à¦°à§‡à¦Ÿ\", \"à¦¨à¦¾à¦‡à¦Ÿ à¦®à§‹à¦¡\", \"à¦œà§à¦®\", \"à¦«à§‹à¦•à¦¾à¦¸\",\n",
    "        \"à¦«à¦Ÿà§‹ à¦•à§‹à§Ÿà¦¾à¦²à¦¿à¦Ÿà¦¿\", \"à¦­à¦¿à¦¡à¦¿à¦“ à¦•à§‹à§Ÿà¦¾à¦²à¦¿à¦Ÿà¦¿\"\n",
    "    ],\n",
    "    \"BUILD_QUALITY\": [\n",
    "        \"build quality\", \"build\", \"material\", \"sturdy\", \"strong\", \"durable\", \"finishing\", \"finish\", \"assembly\",\n",
    "        \"plastic\", \"metal\", \"glass\", \"hinge\",\n",
    "        \"à¦¬à¦¿à¦²à§à¦¡ à¦•à§‹à§Ÿà¦¾à¦²à¦¿à¦Ÿà¦¿\", \"à¦®à§à¦¯à¦¾à¦Ÿà§‡à¦°à¦¿à§Ÿà¦¾à¦²\", \"à¦®à¦œà¦¬à§à¦¤\", \"à¦¶à¦•à§à¦¤\", \"à¦Ÿà§‡à¦•à¦¸à¦‡\", \"à¦«à¦¿à¦¨à¦¿à¦¶à¦¿à¦‚\", \"à¦…à§à¦¯à¦¾à¦¸à§‡à¦®à§à¦¬à¦²à¦¿\",\n",
    "        \"à¦ªà§à¦²à¦¾à¦¸à§à¦Ÿà¦¿à¦•\", \"à¦®à§‡à¦Ÿà¦¾à¦²\", \"à¦§à¦¾à¦¤à¦¬\", \"à¦—à§à¦²à¦¾à¦¸\", \"à¦¹à¦¿à¦à§à¦œ\"\n",
    "    ],\n",
    "    \"AUDIO\": [\n",
    "        \"audio\", \"sound\", \"speaker\", \"loud\", \"volume\", \"mic\", \"microphone\", \"call quality\", \"bass\", \"noise\", \"distortion\",\n",
    "        \"earphone\", \"headphone\",\n",
    "        \"à¦…à¦¡à¦¿à¦“\", \"à¦¸à¦¾à¦‰à¦¨à§à¦¡\", \"à¦¸à§à¦ªà¦¿à¦•à¦¾à¦°\", \"à¦­à¦²à¦¿à¦‰à¦®\", \"à¦®à¦¾à¦‡à¦•\", \"à¦•à¦² à¦•à§‹à§Ÿà¦¾à¦²à¦¿à¦Ÿà¦¿\", \"à¦¬à§‡à¦¸\", \"à¦¨à§Ÿà§‡à¦œ\", \"à¦¡à¦¿à¦¸à§à¦Ÿà¦°à¦¶à¦¨\",\n",
    "        \"à¦‡à§Ÿà¦¾à¦°à¦«à§‹à¦¨\", \"à¦¹à§‡à¦¡à¦«à§‹à¦¨\"\n",
    "    ],\n",
    "    \"SOFTWARE\": [\n",
    "        \"software\", \"os\", \"android\", \"ios\", \"update\", \"bug\", \"issue\", \"ui\", \"interface\", \"settings\", \"reset\",\n",
    "        \"language\", \"keyboard\", \"app crash\", \"crash\",\n",
    "        \"à¦¸à¦«à¦Ÿà¦“à§Ÿà§à¦¯à¦¾à¦°\", \"à¦†à¦ªà¦¡à§‡à¦Ÿ\", \"à¦¬à¦¾à¦—\", \"à¦‡à¦¸à§à¦¯à§\", \"à¦‡à¦‰à¦†à¦‡\", \"à¦‡à¦¨à§à¦Ÿà¦¾à¦°à¦«à§‡à¦¸\", \"à¦¸à§‡à¦Ÿà¦¿à¦‚à¦¸\", \"à¦°à¦¿à¦¸à§‡à¦Ÿ\",\n",
    "        \"à¦­à¦¾à¦·à¦¾\", \"à¦•à¦¿à¦¬à§‹à¦°à§à¦¡\", \"à¦•à§à¦°à§à¦¯à¦¾à¦¶\"\n",
    "    ],\n",
    "    \"STORAGE\": [\n",
    "        \"storage\", \"memory\", \"rom\", \"space\", \"internal storage\", \"sd card\", \"expandable\",\n",
    "        \"à¦¸à§à¦Ÿà§‹à¦°à§‡à¦œ\", \"à¦®à§‡à¦®à§‹à¦°à¦¿\", \"à¦¸à§à¦ªà§‡à¦¸\", \"à¦‡à¦¨à§à¦Ÿà¦¾à¦°à¦¨à¦¾à¦²\", \"à¦à¦¸à¦¡à¦¿ à¦•à¦¾à¦°à§à¦¡\", \"à¦à¦•à§à¦¸à¦ªà§‡à¦¨à§à¦¡à§‡à¦¬à¦²\"\n",
    "    ],\n",
    "    \"AUTHENTICITY\": [\n",
    "        \"original\", \"genuine\", \"authentic\", \"real\", \"sealed\", \"brand new\",\n",
    "        \"fake\", \"replica\", \"copy\", \"duplicate\",\n",
    "        \"à¦…à¦°à¦¿à¦œà¦¿à¦¨à¦¾à¦²\", \"à¦œà§‡à¦¨à§à¦‡à¦¨\", \"à¦†à¦¸à¦²\", \"à¦…à¦¥à§‡à¦¨à¦Ÿà¦¿à¦•\", \"à¦¸à¦¿à¦²\", \"à¦¨à¦¤à§à¦¨\",\n",
    "        \"à¦¨à¦•à¦²\", \"à¦«à§‡à¦•\", \"à¦°à§‡à¦ªà§à¦²à¦¿à¦•à¦¾\", \"à¦•à¦ªà¦¿\"\n",
    "    ],\n",
    "\n",
    "    # -------- Fashion & Apparel --------\n",
    "    \"MATERIAL\": [\n",
    "        \"material\", \"fabric\", \"cloth\", \"cotton\", \"polyester\", \"silk\", \"chiffon\", \"denim\", \"leather\", \"faux leather\",\n",
    "        \"stretch\", \"breathable\",\n",
    "        \"à¦®à§à¦¯à¦¾à¦Ÿà§‡à¦°à¦¿à§Ÿà¦¾à¦²\", \"à¦•à¦¾à¦ªà§œ\", \"à¦•à¦¾à¦ªà¦¡à¦¼\", \"à¦¸à§à¦¤à¦¿\", \"à¦•à¦Ÿà¦¨\", \"à¦ªà¦²à¦¿à§Ÿà§‡à¦¸à§à¦Ÿà¦¾à¦°\", \"à¦¸à¦¿à¦²à§à¦•\", \"à¦¶à¦¿à¦«à¦¨\", \"à¦¡à§‡à¦¨à¦¿à¦®\", \"à¦šà¦¾à¦®à§œà¦¾\", \"à¦²à§‡à¦¦à¦¾à¦°\",\n",
    "        \"à¦¸à§à¦Ÿà§à¦°à§‡à¦š\", \"à¦¬à§à¦°à¦¿à¦¦à§‡à¦¬à¦²\"\n",
    "    ],\n",
    "    \"FIT_SIZE\": [\n",
    "        \"size\", \"fit\", \"fitting\", \"loose\", \"tight\", \"small\", \"large\", \"length\", \"measurement\", \"waist\", \"shoulder\", \"sleeve\",\n",
    "        \"xl\", \"xxl\",\n",
    "        \"à¦¸à¦¾à¦‡à¦œ\", \"à¦®à¦¾à¦ª\", \"à¦«à¦¿à¦Ÿ\", \"à¦«à¦¿à¦Ÿà¦¿à¦‚\", \"à¦¢à¦¿à¦²à¦¾\", \"à¦Ÿà¦¾à¦‡à¦Ÿ\", \"à¦›à§‹à¦Ÿ\", \"à¦¬à§œ\", \"à¦²à¦®à§à¦¬à¦¾\", \"à¦®à§‡à¦œà¦¾à¦°à¦®à§‡à¦¨à§à¦Ÿ\", \"à¦¹à¦¾à¦¤à¦¾\", \"à¦•à¦¾à¦à¦§\"\n",
    "    ],\n",
    "    \"DESIGN\": [\n",
    "        \"design\", \"style\", \"look\", \"pattern\", \"print\", \"color\", \"colour\", \"finishing\", \"stitch\", \"stitching\",\n",
    "        \"beautiful\", \"pretty\",\n",
    "        \"à¦¡à¦¿à¦œà¦¾à¦‡à¦¨\", \"à¦¸à§à¦Ÿà¦¾à¦‡à¦²\", \"à¦²à§à¦•\", \"à¦ªà§à¦¯à¦¾à¦Ÿà¦¾à¦°à§à¦¨\", \"à¦ªà§à¦°à¦¿à¦¨à§à¦Ÿ\", \"à¦°à¦‚\", \"à¦•à¦¾à¦²à¦¾à¦°\", \"à¦«à¦¿à¦¨à¦¿à¦¶à¦¿à¦‚\", \"à¦¸à§‡à¦²à¦¾à¦‡\",\n",
    "        \"à¦¸à§à¦¨à§à¦¦à¦°\"\n",
    "    ],\n",
    "    \"DURABILITY\": [\n",
    "        \"durable\", \"long lasting\", \"tear\", \"torn\", \"fade\", \"faded\", \"shrink\", \"shrunk\", \"wash\", \"washing\",\n",
    "        \"à¦Ÿà§‡à¦•à¦¸à¦‡\", \"à¦Ÿà§‡à¦•à§‡\", \"à¦›à¦¿à¦à§œà§‡\", \"à¦«à¦¾à¦Ÿà¦¾\", \"à¦°à¦‚ à¦‰à¦ à§‡\", \"à¦«à¦¿à¦•à§‡\", \"à¦¸à¦™à§à¦•à§à¦šà¦¿à¦¤\", \"à¦§à§‹à§Ÿà¦¾\", \"à¦§à§à§Ÿà§‡\"\n",
    "    ],\n",
    "    \"FUNCTIONALITY\": [\n",
    "        \"comfortable\", \"comfort\", \"pocket\", \"zip\", \"zipper\", \"button\", \"buttons\", \"waterproof\", \"warm\", \"soft\",\n",
    "        \"à¦†à¦°à¦¾à¦®\", \"à¦†à¦°à¦¾à¦®à¦¦à¦¾à§Ÿà¦•\", \"à¦ªà¦•à§‡à¦Ÿ\", \"à¦œà¦¿à¦ª\", \"à¦¬à§‹à¦¤à¦¾à¦®\", \"à¦“à§Ÿà¦¾à¦Ÿà¦¾à¦°à¦ªà§à¦°à§à¦«\", \"à¦—à¦°à¦®\", \"à¦¨à¦°à¦®\"\n",
    "    ],\n",
    "\n",
    "    # -------- Beauty & Personal Care --------\n",
    "    \"EFFICACY\": [\n",
    "        \"effective\", \"works\", \"working\", \"result\", \"improve\", \"improved\", \"reduce\", \"treatment\",\n",
    "        \"acne\", \"pimple\", \"spot\", \"glow\", \"glowing\", \"brighten\", \"whitening\",\n",
    "        \"hair fall\", \"dandruff\",\n",
    "        \"à¦•à¦¾à¦°à§à¦¯à¦•à¦°\", \"à¦•à¦¾à¦œ à¦•à¦°à§‡\", \"à¦«à¦²\", \"à¦°à§‡à¦œà¦¾à¦²à§à¦Ÿ\", \"à¦‰à¦¨à§à¦¨à¦¤à¦¿\", \"à¦•à¦®à¦¾à§Ÿ\",\n",
    "        \"à¦¬à§à¦°à¦£\", \"à¦ªà¦¿à¦®à§à¦ªà¦²\", \"à¦¦à¦¾à¦—\", \"à¦—à§à¦²à§‹\", \"à¦‰à¦œà§à¦œà§à¦¬à¦²\", \"à¦«à¦°à§à¦¸à¦¾\",\n",
    "        \"à¦šà§à¦² à¦ªà§œà¦¾\", \"à¦–à§à¦¶à¦•à¦¿\"\n",
    "    ],\n",
    "    \"TEXTURE_SMELL\": [\n",
    "        \"smell\", \"scent\", \"fragrance\", \"perfume\", \"odor\", \"texture\",\n",
    "        \"sticky\", \"oily\", \"greasy\", \"dry\", \"absorb\", \"lightweight\",\n",
    "        \"à¦—à¦¨à§à¦§\", \"à¦¸à§à¦—à¦¨à§à¦§\", \"à¦¦à§à¦°à§à¦—à¦¨à§à¦§\", \"à¦¦à§à¦°à§à¦—à¦¨à§à¦§\", \"à¦Ÿà§‡à¦•à§à¦¸à¦šà¦¾à¦°\",\n",
    "        \"à¦šà¦¿à¦Ÿà¦šà¦¿à¦Ÿà§‡\", \"à¦¤à§‡à¦²à¦¤à§‡à¦²à§‡\", \"à¦—à§à¦°à¦¿à¦¸à¦¿\", \"à¦¶à§à¦·à§à¦•\", \"à¦¶à§‹à¦·à§‡\", \"à¦¹à¦¾à¦²à¦•à¦¾\"\n",
    "    ],\n",
    "    \"SUITABILITY\": [\n",
    "        \"suitable\", \"suit\", \"skin type\", \"sensitive\", \"allergy\", \"irritation\", \"rash\",\n",
    "        \"dry skin\", \"oily skin\",\n",
    "        \"à¦‰à¦ªà¦¯à§‹à¦—à§€\", \"à¦¸à§à¦•à¦¿à¦¨ à¦Ÿà¦¾à¦‡à¦ª\", \"à¦¸à§‡à¦¨à§à¦¸à¦¿à¦Ÿà¦¿à¦­\", \"à¦…à§à¦¯à¦¾à¦²à¦¾à¦°à§à¦œà¦¿\", \"à¦œà§à¦¬à¦¾à¦²à¦¾\", \"à¦°â€à§à¦¯à¦¾à¦¶\",\n",
    "        \"à¦¡à§à¦°à¦¾à¦‡ à¦¸à§à¦•à¦¿à¦¨\", \"à¦…à§Ÿà§‡à¦²à¦¿ à¦¸à§à¦•à¦¿à¦¨\"\n",
    "    ],\n",
    "\n",
    "    # -------- Home, Living & Appliances --------\n",
    "    \"AESTHETICS\": [\n",
    "        \"aesthetic\", \"aesthetics\", \"look\", \"looks\", \"beautiful\", \"premium\", \"modern\", \"design\",\n",
    "        \"à¦¡à§‡à¦•à¦°\", \"à¦¡à§‡à¦•à§‹à¦°\", \"à¦¦à§‡à¦–à¦¤à§‡\", \"à¦²à§à¦•\", \"à¦¸à§à¦¨à§à¦¦à¦°\", \"à¦ªà§à¦°à¦¿à¦®à¦¿à§Ÿà¦¾à¦®\", \"à¦†à¦§à§à¦¨à¦¿à¦•\"\n",
    "    ],\n",
    "    \"INSTALLATION\": [\n",
    "        \"install\", \"installation\", \"setup\", \"set up\", \"mount\", \"fit\", \"fitting\", \"manual\", \"instruction\",\n",
    "        \"screw\", \"bracket\",\n",
    "        \"à¦‡à¦¨à¦¸à§à¦Ÿà¦²\", \"à¦‡à¦¨à¦¸à§à¦Ÿà¦²à§‡à¦¶à¦¨\", \"à¦¸à§‡à¦Ÿà¦†à¦ª\", \"à¦²à¦¾à¦—à¦¾à¦¨à§‹\", \"à¦«à¦¿à¦Ÿà¦¿à¦‚\", \"à¦®à§à¦¯à¦¾à¦¨à§à§Ÿà¦¾à¦²\", \"à¦¨à¦¿à¦°à§à¦¦à§‡à¦¶à¦¨à¦¾\",\n",
    "        \"à¦¸à§à¦•à§à¦°à§\", \"à¦¬à§à¦°à§à¦¯à¦¾à¦•à§‡à¦Ÿ\"\n",
    "    ],\n",
    "    \"DIMENSIONS\": [\n",
    "        \"dimension\", \"dimensions\", \"size\", \"width\", \"height\", \"depth\", \"capacity\", \"liter\", \"litre\", \"inch\", \"cm\", \"mm\",\n",
    "        \"à¦®à¦¾à¦ª\", \"à¦¡à¦¾à¦‡à¦®à§‡à¦¨à¦¶à¦¨\", \"à¦¦à§ˆà¦°à§à¦˜à§à¦¯\", \"à¦ªà§à¦°à¦¸à§à¦¥\", \"à¦‰à¦šà§à¦šà¦¤à¦¾\", \"à¦•à§à¦¯à¦¾à¦ªà¦¾à¦¸à¦¿à¦Ÿà¦¿\", \"à¦²à¦¿à¦Ÿà¦¾à¦°\", \"à¦‡à¦à§à¦šà¦¿\", \"à¦¸à§‡à¦®à¦¿\", \"à¦®à¦¿à¦®à¦¿\"\n",
    "    ],\n",
    "\n",
    "    # -------- Food & Grocery --------\n",
    "    \"TASTE_FLAVOR\": [\n",
    "        \"taste\", \"flavor\", \"flavour\", \"delicious\", \"tasty\", \"spicy\", \"hot\", \"sweet\", \"salty\", \"bitter\",\n",
    "        \"à¦¸à§à¦¬à¦¾à¦¦\", \"à¦Ÿà§‡à¦¸à§à¦Ÿ\", \"à¦®à¦œà¦¾\", \"à¦à¦¾à¦²\", \"à¦—à¦°à¦®\", \"à¦®à¦¿à¦·à§à¦Ÿà¦¿\", \"à¦¨à§‹à¦¨à¦¤à¦¾\", \"à¦¤à¦¿à¦¤à¦¾\"\n",
    "    ],\n",
    "    \"FRESHNESS\": [\n",
    "        \"fresh\", \"freshness\", \"stale\", \"rotten\", \"spoiled\", \"smelly\", \"crispy\",\n",
    "        \"à¦Ÿà¦¾à¦Ÿà¦•à¦¾\", \"à¦«à§à¦°à§‡à¦¶\", \"à¦¬à¦¾à¦¸à¦¿\", \"à¦ªà¦šà¦¾\", \"à¦¨à¦·à§à¦Ÿ\", \"à¦¦à§à¦°à§à¦—à¦¨à§à¦§\", \"à¦•à§à§œà¦•à§à§œà§‡\", \"à¦•à§à§œà¦•à§à§œà§‡ à¦¨à§Ÿ\"\n",
    "    ],\n",
    "    \"QUALITY\": [\n",
    "        \"quality\", \"purity\", \"pure\", \"ingredients\", \"authentic\", \"adulterated\",\n",
    "        \"à¦®à¦¾à¦¨\", \"à¦–à¦¾à¦à¦Ÿà¦¿\", \"à¦ªà¦¿à¦“à¦°\", \"à¦‰à¦ªà¦¾à¦¦à¦¾à¦¨\", \"à¦­à§‡à¦œà¦¾à¦²\", \"à¦…à¦¥à§‡à¦¨à¦Ÿà¦¿à¦•\"\n",
    "    ],\n",
    "    \"EXPIRY\": [\n",
    "        \"expiry\", \"expire\", \"expired\", \"best before\", \"mfg\", \"manufacture date\", \"date\",\n",
    "        \"à¦®à§‡à§Ÿà¦¾à¦¦\", \"à¦®à§‡à¦¯à¦¼à¦¾à¦¦\", \"à¦à¦•à§à¦¸à¦ªà¦¾à§Ÿà¦¾à¦°à¦¿\", \"à¦à¦•à§à¦¸à¦ªà¦¾à¦¯à¦¼à¦¾à¦°à¦¿\", \"à¦¤à¦¾à¦°à¦¿à¦–\", \"à¦‰à§à¦ªà¦¾à¦¦à¦¨\"\n",
    "    ],\n",
    "\n",
    "    # -------- Automotive --------\n",
    "    \"COMPATIBILITY\": [\n",
    "        \"compatible\", \"compatibility\", \"fitment\", \"fit\", \"model match\", \"model\", \"match\", \"fits\",\n",
    "        \"car\", \"bike\", \"motorcycle\",\n",
    "        \"à¦•à¦®à§à¦ªà§à¦¯à¦¾à¦Ÿà¦¿à¦¬à¦²\", \"à¦•à¦®à§à¦ªà§à¦¯à¦¾à¦Ÿà¦¿à¦¬à¦¿à¦²à¦¿à¦Ÿà¦¿\", \"à¦«à¦¿à¦Ÿà¦®à§‡à¦¨à§à¦Ÿ\", \"à¦®à¦¿à¦²\", \"à¦®à¦¿à¦²à§‡\", \"à¦®à¦¡à§‡à¦²\", \"à¦«à¦¿à¦Ÿ\", \"à¦«à¦¿à¦Ÿ à¦¹à§Ÿ\",\n",
    "        \"à¦—à¦¾à§œà¦¿\", \"à¦¬à¦¾à¦‡à¦•\", \"à¦®à§‹à¦Ÿà¦°\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "COMPOUND_MARKERS = set(\n",
    "    \"but however though although yet still except whereas kintu tobe jodio ar ebong\"\n",
    "    \" à¦•à¦¿à¦¨à§à¦¤à§ à¦¤à¦¬à§‡ à¦¯à¦¦à¦¿à¦“ à¦…à¦¥à¦š à¦¤à¦¬à§à¦“ à¦à¦¬à¦‚ à¦†à¦°\".split()\n",
    ")\n",
    "\n",
    "def aspect_categories(norm: str) -> set:\n",
    "    hits = set()\n",
    "    for cat, kws in ASPECTS.items():\n",
    "        for kw in kws:\n",
    "            if kw in norm:\n",
    "                hits.add(cat)\n",
    "                break\n",
    "    return hits\n",
    "\n",
    "def content_token_count(norm: str) -> int:\n",
    "    toks = norm.split()\n",
    "    c = 0\n",
    "    for t in toks:\n",
    "        if t in STOPWORDS:\n",
    "            continue\n",
    "        if t in GENERIC_TOKENS:\n",
    "            continue\n",
    "        if t.isdigit():\n",
    "            continue\n",
    "        if len(t) <= 2:\n",
    "            continue\n",
    "        c += 1\n",
    "    return c\n",
    "\n",
    "def is_generic(norm: str) -> bool:\n",
    "    if not norm:\n",
    "        return True\n",
    "    if norm in GENERIC_PHRASES:\n",
    "        return True\n",
    "    toks = norm.split()\n",
    "    cc = content_token_count(norm)\n",
    "    asp = aspect_categories(norm)\n",
    "\n",
    "    # Remove very short generic lines like: \"good\", \"awesome\", \"à¦­à¦¾à¦²à§‹\", \"very good product\"\n",
    "    if len(toks) <= 3 and cc < 2 and len(asp) == 0:\n",
    "        return True\n",
    "\n",
    "    # If mostly generic tokens and no aspects, remove\n",
    "    if len(toks) <= 6 and len(asp) == 0:\n",
    "        ratio_generic = sum(t in GENERIC_TOKENS for t in toks) / max(1, len(toks))\n",
    "        if ratio_generic >= 0.6 and cc < 2:\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def is_compound(norm: str, raw: str) -> bool:\n",
    "    # marker-based\n",
    "    toks = set(norm.split())\n",
    "    if toks & COMPOUND_MARKERS:\n",
    "        return True\n",
    "    # punctuation-based (often indicates multiple clauses)\n",
    "    if any(sep in raw for sep in [\",\", \";\", \"à¥¤\", \"!\", \"?\"]):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def keep_for_absa(raw: str) -> bool:\n",
    "    norm = normalize_text(raw)\n",
    "    if is_generic(norm):\n",
    "        return False\n",
    "\n",
    "    toks = norm.split()\n",
    "    cats = aspect_categories(norm)\n",
    "    cc = content_token_count(norm)\n",
    "\n",
    "    # Needs at least some aspect cue OR at least 2 non-generic content tokens\n",
    "    has_aspect = (len(cats) > 0) or (cc >= 2)\n",
    "    if not has_aspect:\n",
    "        return False\n",
    "\n",
    "    if ABSA_FILTER_LEVEL == \"balanced\":\n",
    "        # Keep: compound OR detailed OR aspect-specific\n",
    "        if is_compound(norm, raw) and len(toks) >= 5:\n",
    "            return True\n",
    "        if len(toks) >= 8:\n",
    "            return True\n",
    "        if len(cats) > 0 and len(toks) >= 3:\n",
    "            return True\n",
    "        if cc >= 3 and len(toks) >= 5:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    # STRICT (recommended): keep multi-aspect OR (compound + aspect + enough length)\n",
    "    if len(cats) >= 2:\n",
    "        return True\n",
    "    if len(cats) >= 1 and is_compound(norm, raw) and len(toks) >= 8:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "mask_absa = df_dedup_emoji_contact[TEXT_COL].astype(str).apply(keep_for_absa)\n",
    "\n",
    "df_absa_ready = df_dedup_emoji_contact.loc[mask_absa].reset_index(drop=True)\n",
    "df_removed_absa = df_dedup_emoji_contact.loc[~mask_absa]\n",
    "\n",
    "df_absa_ready.to_csv(OUT_ABSA_PATH, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"\\n=== ABSA Filtering ===\")\n",
    "print(\"Filter level:\", ABSA_FILTER_LEVEL)\n",
    "print(\"Before:\", len(df_dedup_emoji_contact))\n",
    "print(\"Removed:\", int((~mask_absa).sum()))\n",
    "print(\"Kept:\", len(df_absa_ready))\n",
    "print(\"Saved:\", OUT_ABSA_PATH)\n",
    "\n",
    "print(\"\\nExamples removed:\")\n",
    "print(df_removed_absa[TEXT_COL].head(25).to_list())\n",
    "\n",
    "print(\"\\nExamples kept:\")\n",
    "print(df_absa_ready[TEXT_COL].head(25).to_list())"
   ],
   "id": "8b241f2914342023",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ABSA Filtering ===\n",
      "Filter level: strict\n",
      "Before: 63946\n",
      "Removed: 32502\n",
      "Kept: 31444\n",
      "Saved: data/processed/dataset_absa_ready_strict.csv\n",
      "\n",
      "Examples removed:\n",
      "['à¦…à¦²à§à¦ª à¦¦à¦¾à¦®à§‡ à¦¦à¦¾à¦°à§à¦¨ à¦à¦•à¦Ÿà¦¾ à¦¸à§à¦®à¦¾à¦°à§à¦Ÿà¦«à§‹à¦¨ ğŸ’™', 'Delay Delivery... Good Product.', 'Poor seller response', 'à¦à¦–à¦¨à§‹ à¦­à¦¾à¦²à§‹ à¦†à¦›à§‡ à¦­à¦¬à¦¿à¦·à§à¦¯à¦¤à§‡ à¦•à¦¿ à¦¹à¦¬à§‡ à¦¸à§‡à¦Ÿà¦¾ à¦¦à§‡à¦–à¦¾à¦° à¦¬à¦¿à¦·à¦¯à¦¼', 'bought it for my mother..\\n\\nso far so good.', 'good product for me thanks seller', 'Fast delivery and good product.', 'good quality product', 'à¦…à¦¸à¦¾à¦§à¦¾à¦°à¦£,,,!!', 'good rider', 'Got it within one day, working good.', 'intact,original product', 'Darun phone', 'ink discount a pailam', 'varryGood  product...â¤ï¸\\n100/100%  Original product. â¤ï¸\\nThankss DarazMoll .. Thankss Realme.â¤ï¸ğŸ’', 'realme c55 hate paye ank happy thanks daraz & realme k over all good', 'realme c55 hate paye ank happy thanks daraz & realme k', 'à¦…à¦¨à§‡à¦• à¦ªà¦›à¦¨à§à¦¦ à¦¹à§Ÿà§‡à¦›à§‡', 'Thank you daraz for your fast delivary ğŸ«°', 'valo..nite paren sobai...ğŸ¤—', 'à§§ à¦¦à¦¿à¦¨à§‡à¦‡ à¦¡à§‡à¦²à¦¿à¦­à¦¾à¦°à¦¿ à¦ªà§‡à§Ÿà§‡à¦›à¦¿', 'very good suggested', 'good you can take', 'thanks to daraz', \"I'm happy\"]\n",
      "\n",
      "Examples kept:\n",
      "['à¦…à¦¸à¦¾à¦§à¦¾à¦°à¦£ à¦«à§‹à¦¨à¥¤à¦…à¦¨à§‡à¦• à¦ªà¦›à¦¨à§à¦¦ à¦¹à¦¯à¦¼à§‡à¦›à§‡à¥¤à¦à¦•à¦¦à¦® à¦…à¦¥à§‡à¦¨à¦Ÿà¦¿à¦• à¦¶à¦¾à¦“à¦®à¦¿ à¦«à§‹à¦¨ à¦–à§à¦¬ à¦¸à§à¦¨à§à¦¦à¦° à¦­à¦¾à¦¬à§‡ à¦ªà§à¦¯à¦¾à¦•à§‡à¦Ÿ à¦•à¦°à¦¾ à¦›à¦¿à¦²à¥¤48 à¦˜à¦£à§à¦Ÿà¦¾à¦¯à¦¼ à¦¡à§‡à¦²à¦¿à¦­à¦¾à¦°à¦¿ à¦ªà§‡à¦¯à¦¼à§‡à¦›à¦¿à¥¤à¦°à¦¾à¦‡à¦¡à¦¾à¦° à¦­à¦¾à¦‡ à¦…à¦¨à§‡à¦• à¦­à¦¾à¦²à§‹ à¦›à¦¿à¦² à¦¤à¦¾à¦° à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦°à§‡ à¦†à¦®à¦¿ à¦®à§à¦—à§à¦§à¥¤\\nà¦à¦•à¦Ÿà¦¾ à¦–à¦¾à¦°à¦¾à¦ª à¦²à¦¾à¦—à¦¾ à¦¦à¦¿à¦• à¦¹à¦²à§‹ à¦®à§‹à¦¬à¦¾à¦‡à¦²à§‡à¦° à¦¸à¦¾à¦¥à§‡ à¦•à§‹à¦¨à§‹ à¦•à¦­à¦¾à¦° à¦¬à¦¾ à¦—à§à¦²à¦¾à¦¸ à¦ªà§à¦°à¦Ÿà§‡à¦•à§à¦Ÿà¦° à¦¦à§‡à¦¯à¦¼ à¦¨à¦¾à¦‡ à¦¶à¦¾à¦“à¦®à¦¿à¥¤à¦à¦›à¦¾à¦¡à¦¼à¦¾ à¦¸à¦¬ à¦•à¦¿à¦›à§ à¦­à¦¾à¦²à§‹ à§§à§¦/à§§à§¦ à¦ªà¦£à§à¦¯à¥¤ â¤ï¸â¤ï¸â¤ï¸â¤ï¸', \"Phone is good according to my uses, Upgraded from Realme C11 2020, Except camera it's a good bump. \\nGot a faster delivery within 12 hrs.\", 'Super Fast Delivery ,11200 TK te pailam', 'authentic product', 'Bought this phone from Mi official store of Daraz. Costed less than the market price.\\nThe delivery time was less than 24 hours.', 'à¦¡à§‡à¦²à¦¿à¦­à¦¾à¦°à§€ à¦¬à¦¾ à¦ªà§à¦°à¦¡à¦¾à¦•à§à¦Ÿ à¦¨à¦¿à§Ÿà§‡ à¦•à§‹à¦¨ à¦•à¦¥à¦¾ à¦¨à§‡à¦‡ à¦¬à§‡à¦¶ à¦­à¦¾à¦²à§‹ à¦•à¦¿à¦¨à§à¦¤à§ 5G à¦«à§‹à¦¨ à¦²à§‡à¦–à¦¾ à¦¦à§‡à¦–à§‡ à¦•à¦¿à¦¨à¦²à¦¾à¦® à¦•à§‹à¦¥à¦¾à¦“ à¦à¦°à¦•à¦® à¦•à¦¿à¦›à§ à¦ªà§‡à¦²à¦¾à¦® à¦¨à¦¾\\u200dà¥¤ à¦†à¦¸à¦²à§‡ à¦•à¦¿ 5G ????', 'I do not receive any warranty card with this Phone??', 'Wow...  What The Phone..... 100% Genuine Product & official phone... Thanks Daraz and MI\\n... Delivery Is so Fast..... Xiaomi Is The Best Phone In Bangladesh....', 'When I received the product did not get any invoice with it. After contacting daraz they provide me an e-invoice. Besides the bettary backup is not well performed as expected.', 'Phone is good according to my uses, Upgraded from Redmi Note 7s, \\nGot a faster delivery within 12 hrs.', 'Authentic and genuine product. \\nà¦à¦‡ à¦¬à¦¾à¦œà§‡à¦Ÿ à¦ à¦–à§à¦¬à¦‡ à¦­à¦¾à¦²à§‹ à¦«à§‹à¦¨à¥¤ \\nRecommended!', 'Reviewed by Mr. Shanto DasğŸ˜\\nà¦…à¦¨à§‡à¦•à¦¦à¦¿à¦¨ à¦§à¦°à§‡ à¦«à§‹à¦¨ à¦•à¦¿à¦¨à¦¬à§‹ à¦¬à¦²à§‡ à¦­à¦¾à¦¬à¦›à¦¿à¦²à¦¾à¦® à¦•à¦¿à¦¨à§à¦¤à§ à¦ªà¦°à§€à¦•à§à¦·à¦¾à¦° à¦•à¦¾à¦°à¦£à§‡ à¦•à§‡à¦¨à¦¾ à¦¹à¦šà§à¦›à¦¿à¦²à§‹ à¦¨à¦¾à¥¤ à¦¦à¦¾à¦°à¦¾à¦œà§‡ à¦¸à§à¦Ÿà¦•à§‡ à¦›à¦¿à¦²à§‹à¦¨à¦¾ à¦®à¦¡à§‡à¦²à¦Ÿà¦¾ à¦¦à§€à¦°à§à¦˜à¦¦à¦¿à¦¨, à¦…à¦¬à¦¶à§‡à¦·à§‡ à§§à§¦à¦‡ à¦œà§à¦¨ à¦¦à§‡à¦–à¦²à¦¾à¦® à¦¶à¦ªà§‡ à¦à¦¡ à¦¹à¦‡à¦›à§‡ à¦•à¦¿à¦¨à§à¦¤à§ à¦¸à§à¦Ÿà¦• à¦¨à§‡à¦‡à¥¤ à¦‰à¦‡à¦¶à¦²à¦¿à¦·à§à¦Ÿ à¦•à¦°à§‡ à¦°à¦¾à¦–à¦²à¦¾à¦®ğŸ˜‰ à§§à§¨ à¦‡ à¦œà§à¦¨ à¦¬à¦¿à¦•à¦¾à¦²à§‡ à¦•à¦¿ à¦®à¦¨à§‡ à¦•à¦°à§‡ à¦¢à§à¦•à§‡ à¦¦à§‡à¦–à¦¿ à¦®à¦¾à¦² à¦¸à§à¦Ÿà¦•à§‡,à¦ªà¦›à¦¨à§à¦¦à¦¸à¦‡ à¦°à¦‚ à¦¬à§à¦²à¦¾à¦•à¦“ à¦†à¦›à§‡ à¦†à¦° à¦¦à¦¾à¦® à§§à§®,à§ªà§­à§ª/- à¦Ÿà¦¾à¦•à¦¾ğŸ˜± à¦ˆà¦¦ à¦­à¦¾à¦‰à¦šà¦¾à¦° à¦†à¦° à¦•à§Ÿà§‡à¦¨ à¦à¦¡ à¦•à¦°à§‡ à§§à§­,à§­à§®à§«/- à¦Ÿà¦¾à¦•à¦¾à§Ÿ à¦•à§à¦¯à¦¾à¦¶ à¦…à¦¨ à¦¡à§‡à¦²à¦¿à¦­à¦¾à¦°à¦¿à¦¤à§‡ à¦…à¦°à§à¦¡à¦¾à¦° à¦•à¦°à¦²à¦¾à¦® à¦¤à¦–à¦¨à¦‡à¥¤ à¦¬à§‡à¦¶ à¦­à¦¾à¦²à§‹ à¦¡à¦¿à¦²ğŸ§¡ à§§ à¦˜à¦¨à§à¦Ÿà¦¾ à¦ªà¦° à¦¢à§à¦•à§‡ à¦¦à§‡à¦–à¦¿ à¦¸à§à¦Ÿà¦• à¦¨à§‡à¦‡ à¦†à¦°ğŸ˜‚ à¦ªà¦°à§‡à¦°à¦¦à¦¿à¦¨ à¦¦à§‡à¦–à¦²à¦¾à¦® à§§à§¯,à§«à§¬à§¨à§³ à¦¤à§‡ à¦¸à§à¦Ÿà¦• à¦†à¦¸à¦›à§‡ğŸ¤£ à¦†à¦®à¦¿ à¦†à¦—à§‡à¦° à¦¦à¦¿à¦¨ à¦…à¦°à§à¦¡à¦¾à¦° à¦•à¦°à¦¾à§Ÿ à§¨à§¨à§§à§«à§³ à¦•à¦® à¦ªà§œà¦›à§‡ à¦…à¦«à¦¿à¦¶à¦¿à§Ÿà¦¾à¦² à¦ªà§à¦°à¦¾à¦‡à¦¸ à¦¥à§‡à¦•à§‡à¥¤ à¦¤à¦¬à§‡ à§§à§© à¦¤à¦¾à¦°à¦¿à¦– à¦ªà§à¦¯à¦¾à¦•à§‡à¦œà¦¿à¦‚ à¦•à¦°à§‡ à§§à§©,à§§à§ª,à§§à§« à¦¤à¦¾à¦°à¦¿à¦– à§©à¦¦à¦¿à¦¨ à¦“à§Ÿà¦¾à¦°à¦¹à¦¾à¦‰à¦œà§‡ à¦«à§‡à¦²à§‡ à¦°à¦¾à¦–à¦›à¦¿à¦²à§‹ à¦¦à¦¾à¦°à¦¾à¦œà¥¤ à¦†à¦° à§§ à¦¦à¦¿à¦¨ à¦«à§‡à¦²à§‡ à¦°à¦¾à¦–à¦²à§‡à¦‡ à¦…à¦°à§à¦¡à¦¾à¦°à¦Ÿà¦¾ à¦•à§à¦¯à¦¾à¦¨à§à¦¸à§‡à¦² à¦¹à§Ÿà§‡ à¦¯à§‡à¦¤à§‹ğŸ˜¡ à¦²à¦¾à¦‡à¦­à¦šà§à¦¯à¦¾à¦Ÿ,à¦‡à¦®à§‡à¦‡à¦²,à¦¹à§‡à¦²à§à¦ªà¦²à¦¾à¦‡à¦¨à§‡ à¦•à¦¥à¦¾ à¦¬à¦²à§‡ à¦…à¦¨à§‡à¦• à¦•à¦¾à¦ à¦–à§‹à¦Ÿà§à¦Ÿà¦¾ à¦ªà§‹à§œà¦¾à¦¨à§‹à¦° à¦ªà¦° à§§à§¬à¦‡ à¦œà§à¦¨ à¦°à§‡à¦¡à§‡à¦•à§à¦¸à§‡à¦° à¦•à¦¾à¦›à§‡ à¦¹à¦¸à§à¦¤à¦¾à¦¨à§à¦¤à¦° à¦•à¦°à§‡ à¦¶à¦¿à¦ªà¦¿à¦‚ à¦•à¦°à¦›à§‡ğŸ˜¤ à§§à§® à¦¤à¦¾à¦°à¦¿à¦– à¦¸à¦•à¦¾à¦²à§‡ à¦ªà¦Ÿà§à§Ÿà¦¾à¦–à¦¾à¦²à§€ à¦¸à¦¦à¦° à¦¹à¦¾à¦¬à§‡ à¦†à¦¸à§‡ à¦ªà¦¾à¦°à§à¦¸à§‡à¦² à¦à¦¬à¦‚ à¦¦à§à¦ªà§à¦° à§§à§¨ à¦Ÿà¦¾à§Ÿ à¦†à¦®à¦¾à¦° à¦‰à¦ªà¦œà§‡à¦²à¦¾à§Ÿ à¦à¦¸à§‡ à¦¦à¦¿à§Ÿà§‡ à¦¯à¦¾à§Ÿ à¦¯à¦¦à¦¿à¦“ à¦¹à§‹à¦® à¦¡à§‡à¦²à¦¿à¦­à¦¾à¦°à¦¿ à¦¦à§‡à§Ÿà¦¨à¦¿, à¦¨à¦¿à§Ÿà§‡ à¦†à¦¸à¦¤à§‡ à¦¹à§Ÿà§‡à¦›à§‡ à¦—à¦¿à§Ÿà§‡ğŸ˜¤\\nà¦¸à¦°à§à¦¬à§‹à¦ªà¦°à¦¿, à¦°à§‡à¦Ÿà¦¿à¦‚ ğŸ‘‡\\nâ˜¢ï¸ à¦¦à¦¾à¦°à¦¾à¦œà¦ƒ- à§®/à§§à§¦ (for delay) \\nâ™ˆ à¦°à§‡à¦¡à§‡à¦•à§à¦¸ à¦•à§à¦°à¦¿à§Ÿà¦¾à¦°à¦ƒ- à§­/à§§à§¦\\nğŸ’¸ à¦®à§‚à¦²à§à¦¯à¦ƒ- à§§à§­,à§­à§®à§«à§³', 'à§§à§¦à§¦% à¦…à¦¥à§‡à¦¨à¦Ÿà¦¿à¦• à¦à¦¬à¦‚ à¦…à¦«à¦¿à¦¸à¦¿à§Ÿà¦¾à¦² à¦ªà§à¦°à§‹à¦¡à¦¾à¦•à§à¦Ÿà¥¤\\nà¦à¦‡ à¦¬à¦¾à¦œà§‡à¦Ÿà§‡ à¦–à§à¦¬ à¦­à¦¾à¦²à§‹ à¦à¦•à¦Ÿà¦¿ à¦«à§‹à¦¨à¥¤\\nà¦•à§à¦¯à¦¾à¦®à§‡à¦°à¦¾ à¦­à¦¾à¦²à§‹ à¦¦à¦¾à¦® à¦…à¦¨à§à¦¯à¦¾à§Ÿà§€à¥¤\\nà¦¬à§à¦¯à¦¾à¦Ÿà¦¾à¦°à§€ à¦¬à§à¦¯à¦¾à¦•à¦†à¦ª à¦–à§à¦¬ à¦­à¦¾à¦²à§‹à¥¤\\nà¦«à§‹à¦¨à§‡à¦° à¦¡à¦¿à¦œà¦¾à¦‡à¦¨ à¦“ à¦–à¦¾à¦°à¦¾à¦ª à¦¨à¦¾à¥¤\\nà¦¸à¦¬ à¦¦à¦¿à¦• à¦¬à¦¿à¦¬à§‡à¦šà¦¨à¦¾à§Ÿ à¦–à§à¦¬ à¦­à¦¾à¦²à§‹ à¦à¦•à¦Ÿà¦¿ à¦«à§‹à¦¨ à¦à¦‡ à¦¦à¦¾à¦®à§‡à¥¤\\nà¦§à¦¨à§à¦¯à¦¬à¦¾à¦¦ Realme Bd à¦•à§‡ à¦à¦¬à¦‚ Daraz Bd à¦•à§‡à¥¤', 'I gift my wife ,She is happy and exited,\\nAuthentic and best budgeting phone of this price rangeğŸ’Ÿ', 'best price  is daraz sara emn price  kew dite pare na thanks daraz & realme k keep it up........ company daraz &  realme â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸', 'daraz sara emn price  kew dite pare na thanks daraz & realme k keep it up........ company daraz &  realme â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸', 'à¦…à¦¨à§‡à¦• à¦¸à§à¦¨à§à¦¦à¦° à¦«à§‹à¦¨à¥¤ à¦§à¦¨à§à¦¯à¦¬à¦¾à¦¦ à¦¦à¦¾à¦°à¦¾à¦œ à¦¯à¦¥à¦¾à¦¸à¦®à§Ÿà§‡ à¦¡à§‡à¦²à¦¿à¦­à¦¾à¦°à¦¿ à¦¦à§‡à¦“à§Ÿà¦¾à¦° à¦œà¦¨à§à¦¯à¥¤', 'great device thanks for realme and daraz great service', 'à¦…à¦¨à§‡à¦• à¦­à¦¾à¦²à§‹ à¦«à§‹à¦¨ à¦–à§à¦¬ à¦¤à¦¾à¦°à¦¾à¦¤à¦¾à§œà¦¿ à¦¡à§‡à¦²à¦¿à¦­à¦¾à¦°à¦¿ à¦ªà§‡à§Ÿà§‡à¦›à¦¿ à¦§à¦¨à§à¦¯à¦¬à¦¾à¦¦ à¦¸à§‡à¦²à¦¾à¦° à¦•à§‡ à¦§à¦¨à§à¦¯à¦¬à¦¾à¦¦ à¦¦à¦¾à¦°à¦¾à¦œ', 'à¦…à¦°à§à¦¡à¦¾à¦° à¦•à¦°à¦²à¦¾à¦® Rainy Night \\nà¦ªà§‡à¦²à¦¾à¦®à¥¤ Sunshower à¦à¦‡à¦Ÿà¦¾ à¦•à§‡à¦®à¦¨ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦­à¦¾à¦‡', '18521 Tk dia kinlam daraz thake. orginal product pici. chila apnara nita paran, asa kori Thokban na.\\nEi  Price range a best phone.', 'à¦†à¦¸à¦¸à¦¾à¦²à¦¾à¦®à§ à¦†à¦²à¦¾à¦‡à¦•à§à¦® à¦“à¦¯à¦¼à¦¾ à¦°à¦¾à¦¹à¦®à¦¾à¦¤à§à¦²à§à¦²à¦¾à¦¹ à¦†à¦²à¦¹à¦¾à¦®à¦¦à§à¦²à¦¿à¦²à§à¦²à¦¾à¦¹ à¦†à¦®à¦¾à¦° à¦¸à§‡à¦Ÿà¦Ÿà¦¿ à¦…à¦¨à§‡à¦• à¦¸à§à¦¨à§à¦¦à¦° à¦¹à¦¯à¦¼à§‡à¦›à§‡ à¦¯à§‡à¦®à¦¨ à¦šà§‡à¦¯à¦¼à§‡à¦›à¦¿ à¦¤à§‡à¦®à¦¨ à¦ªà§‡à¦¯à¦¼à§‡à¦›à¦¿ à¦•à§‹à¦¥à¦¾à¦¯à¦¼ à¦—à¦¾à¦œà¦¾ à¦ à¦¿à¦• à¦†à¦›à§‡ à¦šà¦¾à¦‡à¦²à§‡ à¦†à¦ªà¦¨à¦¾à¦°à¦“ à¦¨à¦¿à¦¤à§‡ à¦ªà¦¾à¦°à§‡à¦¨ à¦¦à¦¾à¦°à¦¾à¦œ à¦°à¦¾à¦‡à¦¡à¦¾à¦° à¦•à§‡ à¦ªà¦•à§à¦· à¦¥à§‡à¦•à§‡ à¦§à¦¨à§à¦¯à¦¬à¦¾à¦¦', \"packaging is superb!\\ngot authentic products.\\n\\nbut I didn't get invoice with the parcel. can you pls send it for me?\\nthanks\", 'I was optimistic about the 6/128gb performance, but it was not up to the mark. Lag on touch. Totally frustrated.', 'If you are okay to use big size phone with average uses, than it is a good phone. Canâ€™t use it in one hand.']\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T14:05:04.399992Z",
     "start_time": "2025-12-13T14:05:04.274036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "WORD_RE = re.compile(r\"[A-Za-z0-9\\u0980-\\u09FF]+\")\n",
    "\n",
    "def word_count(text):\n",
    "    if not isinstance(text, str):\n",
    "        return 0\n",
    "    return len(WORD_RE.findall(text))\n",
    "\n",
    "df_absa_ready[\"word_count\"] = df_absa_ready[TEXT_COL].apply(word_count)\n",
    "df_filtered = df_absa_ready[df_absa_ready[\"word_count\"].between(4, 25, inclusive=\"both\")].reset_index(drop=True)\n",
    "\n",
    "print(\"Rows:\", len(df_absa_ready))\n",
    "print(\"Word count stats:\")\n",
    "print(df_absa_ready[\"word_count\"].describe())\n",
    "print(\"After :\", len(df_filtered))\n",
    "# print(\"\\nTop 10 longest reviews by word count:\")\n",
    "# print(df_absa_ready.sort_values(\"word_count\", ascending=False)[[TEXT_COL, \"word_count\"]].head(10).to_string(index=False))\n"
   ],
   "id": "80456015f5ea8882",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 31444\n",
      "Word count stats:\n",
      "count    31444.000000\n",
      "mean        20.056227\n",
      "std         17.619293\n",
      "min          1.000000\n",
      "25%         10.000000\n",
      "50%         15.000000\n",
      "75%         25.000000\n",
      "max        354.000000\n",
      "Name: word_count, dtype: float64\n",
      "After : 23458\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T14:28:25.341520Z",
     "start_time": "2025-12-13T14:28:25.180627Z"
    }
   },
   "cell_type": "code",
   "source": "df_filtered.to_csv(DATA_PROCESSED / f\"dataset_absa_ready_{ABSA_FILTER_LEVEL}_wc_filtered.csv\", index=False, encoding=\"utf-8\")",
   "id": "3200b19487d03b57",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T14:14:18.991696Z",
     "start_time": "2025-12-13T14:14:18.919548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if \"Sentiment\" in df_filtered.columns:\n",
    "    print(\"\\nSentiment distribution:\")\n",
    "    print(df_filtered[\"Sentiment\"].value_counts(dropna=False))\n",
    "\n",
    "if \"Emotion\" in df_filtered.columns:\n",
    "    print(\"\\nEmotion distribution:\")\n",
    "    print(df_filtered[\"Emotion\"].value_counts(dropna=False))\n",
    "\n",
    "if \"Product Name\" in df_filtered.columns:\n",
    "    print(\"\\nUnique Product Names:\", df_filtered[\"Product Name\"].nunique())\n",
    "if \"Product Category\" in df_filtered.columns:\n",
    "    print(\"Unique Product Categories:\", df_filtered[\"Product Category\"].nunique())\n",
    "if \"Review\" in df_filtered.columns:\n",
    "    print(\"\\nUnique review distribution:\", df_filtered[\"Review\"].nunique())"
   ],
   "id": "2c1a6f2831184847",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentiment distribution:\n",
      "Sentiment\n",
      "Positive    19327\n",
      "Negative     4131\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Emotion distribution:\n",
      "Emotion\n",
      "Happy      14905\n",
      "Love        4422\n",
      "Sadness     2585\n",
      "Anger       1108\n",
      "Fear         438\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique Product Names: 1993\n",
      "Unique Product Categories: 141\n",
      "\n",
      "Unique review distribution: 23458\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T02:38:57.489025Z",
     "start_time": "2025-12-14T02:38:53.964048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "from rapidfuzz import fuzz\n",
    "\n",
    "# Load your latest filtered dataset\n",
    "# df_filtered = pd.read_csv(\"data/processed/dataset_absa_ready_strict_wc_filtered.csv\")\n",
    "\n",
    "def fuzzy_deduplicate(df, text_col=\"Review\", threshold=100):\n",
    "    \"\"\"\n",
    "    Removes fuzzy duplicates using a length-sorted window approach.\n",
    "    Complexity is reduced from O(N^2) to roughly O(N * window_size).\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    print(f\"Starting fuzzy deduplication on {len(df)} rows...\")\n",
    "\n",
    "    # 1. Create a working copy and add a length column for sorting\n",
    "    df_proc = df.copy()\n",
    "    df_proc[\"_len\"] = df_proc[text_col].astype(str).str.len()\n",
    "\n",
    "    # 2. Sort by length: matching text usually has similar length\n",
    "    # This groups \"Good product\" and \"Good product.\" together\n",
    "    df_proc = df_proc.sort_values(\"_len\").reset_index(drop=True)\n",
    "\n",
    "    to_drop = set()\n",
    "    texts = df_proc[text_col].astype(str).tolist()\n",
    "    n = len(texts)\n",
    "\n",
    "    # 3. Iterate through rows\n",
    "    for i in range(n):\n",
    "        if i in to_drop:\n",
    "            continue\n",
    "\n",
    "        current_text = texts[i]\n",
    "        current_len = len(current_text)\n",
    "\n",
    "        # Optimization: Stop looking if the next row is too much longer to match\n",
    "        # If threshold is 90%, length difference > 15-20% usually implies a mismatch.\n",
    "        # We use a loose buffer here.\n",
    "        max_len_diff = int(current_len * 0.2) + 5\n",
    "\n",
    "        # Look ahead at the next 50 neighbors (Window Size)\n",
    "        # You can increase range(i+1, min(i+50, n)) if you want to be more thorough\n",
    "        for j in range(i + 1, min(i + 100, n)):\n",
    "            if j in to_drop:\n",
    "                continue\n",
    "\n",
    "            next_text = texts[j]\n",
    "            next_len = len(next_text)\n",
    "\n",
    "            # Break window early if length difference is too large\n",
    "            if next_len - current_len > max_len_diff:\n",
    "                break\n",
    "\n",
    "            # Calculate Similarity Ratio\n",
    "            # fuzz.ratio is fast and handles punctuation/case diffs well.\n",
    "            # Example: \"Good phone\" vs \"Good phone.\" = ~95% match\n",
    "            score = fuzz.ratio(current_text, next_text)\n",
    "\n",
    "            if score >= threshold:\n",
    "                to_drop.add(j)\n",
    "\n",
    "        # Progress tracker\n",
    "        if i % 5000 == 0 and i > 0:\n",
    "            print(f\"Processed {i}/{n} rows...\")\n",
    "\n",
    "    # 4. Remove duplicates and clean up\n",
    "    df_final = df_proc.drop(index=list(to_drop)).drop(columns=[\"_len\"])\n",
    "\n",
    "    print(f\"Finished in {time.time() - start_time:.2f}s\")\n",
    "    print(f\"Removed {len(to_drop)} duplicates.\")\n",
    "    return df_final.reset_index(drop=True)\n",
    "\n",
    "# --- EXECUTION ---\n",
    "df_fuzzy_dedup = fuzzy_deduplicate(df_filtered, text_col=\"Review\", threshold=90)\n",
    "\n",
    "# Save result\n",
    "df_fuzzy_dedup.to_csv(\"data/processed/dataset_fuzzy_dedup.csv\", index=False)\n",
    "print(f\"New Shape: {df_fuzzy_dedup.shape}\")"
   ],
   "id": "ceddc5818f43d8bf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fuzzy deduplication on 23458 rows...\n",
      "Processed 5000/23458 rows...\n",
      "Processed 10000/23458 rows...\n",
      "Processed 15000/23458 rows...\n",
      "Processed 20000/23458 rows...\n",
      "Finished in 3.39s\n",
      "Removed 50 duplicates.\n",
      "New Shape: (23408, 8)\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T02:51:55.534375Z",
     "start_time": "2025-12-14T02:51:55.372778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- STRATEGIC DOWNSAMPLING ---\n",
    "\n",
    "# 1. Separate classes\n",
    "df_pos = df_fuzzy_dedup[df_fuzzy_dedup[\"Sentiment\"] == \"Positive\"]\n",
    "df_neg = df_fuzzy_dedup[df_fuzzy_dedup[\"Sentiment\"] == \"Negative\"]\n",
    "\n",
    "# 2. Decide how many positives to keep (e.g., 2x the negatives)\n",
    "target_neg_count = 4000\n",
    "target_pos_count = target_neg_count * 2\n",
    "\n",
    "print(f\"Negatives (Original): {len(df_neg)}\")\n",
    "print(f\"Negatives (Target): {target_neg_count}\")\n",
    "print(f\"Positives (Original): {len(df_pos)}\")\n",
    "print(f\"Positives (Target): {target_pos_count}\")\n",
    "\n",
    "# 3. Randomly sample the positives & negatives\n",
    "df_neg_downsampled = df_neg.sample(n=target_neg_count, random_state=42)\n",
    "df_pos_downsampled = df_pos.sample(n=target_pos_count, random_state=42)\n",
    "\n",
    "# 4. Combine and Shuffle\n",
    "df_balanced = pd.concat([df_pos_downsampled, df_neg_downsampled]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Save final ready-to-train dataset\n",
    "df_balanced.to_csv(\"data/processed/dataset_final_selected.csv\", index=False)\n",
    "\n",
    "print(f\"\\nFinal Dataset Shape: {df_balanced.shape}\")\n",
    "print(df_balanced[\"Sentiment\"].value_counts())"
   ],
   "id": "f155fda86554d1b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negatives (Original): 4129\n",
      "Negatives (Target): 4000\n",
      "Positives (Original): 19279\n",
      "Positives (Target): 8000\n",
      "\n",
      "Final Dataset Shape: (12000, 8)\n",
      "Sentiment\n",
      "Positive    8000\n",
      "Negative    4000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6511432338a89793"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
